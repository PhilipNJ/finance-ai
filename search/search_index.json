{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Finance AI Dashboard","text":"\ud83e\udd16 **AI-Powered Personal Finance Management**  100% Offline | Privacy-First | Self-Adapting  [Get Started](getting-started.md){ .md-button .md-button--primary } [View on GitHub](https://github.com/PhilipNJ/finance-ai){ .md-button }"},{"location":"#what-is-finance-ai-dashboard","title":"What is Finance AI Dashboard?","text":"<p>Finance AI Dashboard is an intelligent personal finance management system that uses local AI agents to automatically extract, organize, and analyze your financial data from any document format.</p> <p>Unlike traditional finance software, Finance AI is built with an AI-first philosophy - the AI agents are not a feature, they ARE the product.</p>"},{"location":"#key-features","title":"Key Features","text":"<p> Multi-Agent AI System :   Three specialized AI agents work together to process your financial documents intelligently.</p> <p> Universal File Support :   Upload CSV, PDF, text files, or even handwritten receipts (with OCR support).</p> <p> Context-Aware Processing :   The LLM understands your documents contextually, not just through pattern matching.</p> <p> Dynamic Database Schema :   Database tables and columns are created automatically based on your data.</p> <p> Interactive Dashboard :   Beautiful visualizations of spending patterns, monthly cashflow, and category breakdowns.</p> <p> 100% Offline &amp; Private :   Everything runs locally - no cloud APIs, no data leaving your machine.</p>"},{"location":"#how-it-works","title":"How It Works","text":"<pre><code>graph TB\n    A[User Uploads File] --&gt; B{Agent 1: Extractor}\n    B --&gt;|Understands Document| C[output_1.json]\n    C --&gt; D{Agent 2: Organizer}\n    D --&gt;|Structures Data| E[organized_*.json]\n    E --&gt; F{Agent 3: Database}\n    F --&gt;|Creates Tables| G[(SQLite DB)]\n    F --&gt;|Writes Records| G\n    G --&gt; H[Interactive Dashboard]\n\n    B -.-&gt;|Uses| LLM[Mistral-7B LLM]\n    D -.-&gt;|Uses| LLM\n\n    style B fill:#e1f5ff,stroke:#0288d1\n    style D fill:#e8f5e9,stroke:#43a047\n    style F fill:#fff3e0,stroke:#fb8c00\n    style LLM fill:#f3e5f5,stroke:#8e24aa</code></pre>"},{"location":"#the-three-agents","title":"The Three Agents","text":"<p>Agent 1: Extractor \ud83d\udd0d :   Reads any document format and uses the LLM to understand context, extract financial entities, and identify document types.</p> <p>Agent 2: Organizer \ud83d\udcca :   Takes extracted data and intelligently organizes it into structured formats (transactions, budgets, accounts, etc.).</p> <p>Agent 3: Database Expert \ud83d\udcbe :   Analyzes organized data, creates necessary database tables and columns dynamically, then writes everything to SQLite.</p> <p>Learn more about the AI architecture \u2192</p>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code># User uploads \"statement.pdf\"\n# Agent 1: Understands it's a bank statement\n# Agent 2: Extracts 42 transactions\n# Agent 3: Writes to database, creates 2 new categories\n\nResult: \u2713 statement.pdf: 42 records processed \ud83e\udd16\n</code></pre>"},{"location":"#why-ai-first","title":"Why AI-First?","text":"<p>Traditional finance software uses rigid rules and pattern matching. Finance AI uses local language models to truly understand your documents:</p> Traditional Approach AI-First Approach Fixed CSV parsers Understands any format Keyword matching Context understanding Manual categorization Intelligent classification Static database schema Self-evolving schema Structured data only Structured + unstructured"},{"location":"#privacy-security","title":"Privacy &amp; Security","text":"<p>Your Data Stays Private</p> <ul> <li>\u2705 100% Offline - No external API calls</li> <li>\u2705 Local Processing - Everything runs on your machine</li> <li>\u2705 No Telemetry - Zero tracking or analytics</li> <li>\u2705 Open Source - Audit the code yourself</li> </ul>"},{"location":"#technology-stack","title":"Technology Stack","text":"<p>The application is built on:</p> <ul> <li>AI Engine: Mistral-7B-Instruct (Q5_0 quantized, ~4.7GB)</li> <li>LLM Runtime: llama-cpp-python for efficient CPU/GPU inference</li> <li>Framework: Python Dash with Plotly visualizations</li> <li>Database: SQLite with dynamic schema evolution</li> <li>Parsing: pandas, pdfplumber, pytesseract (OCR)</li> </ul>"},{"location":"#system-requirements","title":"System Requirements","text":"Requirement Minimum Recommended Python 3.10+ 3.11+ RAM 8GB 16GB Storage 5GB 10GB CPU 4 cores 8+ cores"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li> <p> Get Started</p> <p>Install and run Finance AI in minutes</p> <p> Installation Guide</p> </li> <li> <p> Learn the Architecture</p> <p>Understand how the AI agents work</p> <p> AI Architecture</p> </li> <li> <p> User Guide</p> <p>Learn how to use all features</p> <p> User Guide</p> </li> <li> <p> API Reference</p> <p>Technical documentation for developers</p> <p> API Docs</p> </li> </ul>"},{"location":"#community","title":"Community","text":"<ul> <li>Issues: GitHub Issues</li> <li>Discussions: GitHub Discussions</li> <li>Contributing: Contribution Guidelines</li> </ul> <p>Quick Tip</p> <p>Run <code>python3 preflight_check.py</code> before starting to verify all dependencies are installed correctly.</p>"},{"location":"agent-workflow/","title":"Agent Workflow Technical Guide","text":"<p>This document provides a deep technical dive into how the three-agent system processes financial documents.</p>"},{"location":"agent-workflow/#overview","title":"Overview","text":"<p>The agent workflow is implemented in <code>agents.py</code> and orchestrated by the <code>AgentWorkflow</code> class.</p> <pre><code>graph TB\n    subgraph \"File Upload\"\n        A[User Uploads File] --&gt; B[Dash Callback]\n        B --&gt; C[AgentWorkflow.process_file]\n    end\n\n    subgraph \"Agent Processing\"\n        C --&gt; D[Agent 1: Extract]\n        D --&gt; E[Agent 2: Organize]\n        E --&gt; F[Agent 3: Database]\n    end\n\n    subgraph \"Results\"\n        F --&gt; G[Update Dashboard]\n        F --&gt; H[Cleanup Temp Files]\n    end\n\n    style D fill:#e1f5ff\n    style E fill:#e8f5e9\n    style F fill:#fff3e0</code></pre>"},{"location":"agent-workflow/#agentworkflow-orchestrator","title":"AgentWorkflow Orchestrator","text":""},{"location":"agent-workflow/#initialization","title":"Initialization","text":"<pre><code>class AgentWorkflow:\n    def __init__(self):\n        # Initialize LLM (loads model automatically)\n        self.llm = LLMHandler()\n\n        # Create specialized agents\n        self.extractor = ExtractionAgent(self.llm)\n        self.organizer = OrganizerAgent(self.llm)\n        self.db_agent = DatabaseAgent(self.llm)\n\n        # Create temporary directories\n        self.temp_dir = Path(\"data/temp\")\n        self.temp_dir.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"agent-workflow/#main-process-flow","title":"Main Process Flow","text":"<pre><code>def process_file(self, file_path: str, original_filename: str) -&gt; Dict:\n    \"\"\"\n    Full pipeline: Extract \u2192 Organize \u2192 Database\n    \"\"\"\n    try:\n        # Generate unique session ID\n        session_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n        # Phase 1: Extraction\n        output_1 = self.extractor.extract(file_path, original_filename, session_id)\n        output_1_path = self.temp_dir / f\"output_1_{session_id}.json\"\n        self._save_json(output_1, output_1_path)\n\n        # Phase 2: Organization\n        organized_files = self.organizer.organize(output_1_path, session_id)\n\n        # Phase 3: Database\n        total_records = 0\n        for organized_file in organized_files:\n            records = self.db_agent.write_to_db(organized_file)\n            total_records += records\n\n        # Cleanup\n        self._cleanup_session(session_id)\n\n        return {\n            \"success\": True,\n            \"records\": total_records,\n            \"session_id\": session_id\n        }\n    except Exception as e:\n        return {\n            \"success\": False,\n            \"error\": str(e)\n        }\n</code></pre>"},{"location":"agent-workflow/#agent-1-extractionagent","title":"Agent 1: ExtractionAgent \ud83d\udd0d","text":""},{"location":"agent-workflow/#purpose","title":"Purpose","text":"<p>Universal document reader that handles CSV, PDF, and text files.</p>"},{"location":"agent-workflow/#code-structure","title":"Code Structure","text":"<pre><code>class ExtractionAgent:\n    def __init__(self, llm_handler: LLMHandler):\n        self.llm = llm_handler\n\n    def extract(self, file_path: str, filename: str, session_id: str) -&gt; Dict:\n        \"\"\"\n        Extract data from any file format\n        \"\"\"\n        file_type = Path(file_path).suffix.lower()\n\n        # Step 1: Read raw data\n        if file_type == '.csv':\n            raw_data = self._read_csv(file_path)\n        elif file_type == '.pdf':\n            raw_data = self._read_pdf(file_path)\n        else:\n            raw_data = self._read_text(file_path)\n\n        # Step 2: Enhance with LLM\n        enhanced = self._enhance_with_llm(raw_data, file_type)\n\n        # Step 3: Build output\n        return {\n            \"filename\": filename,\n            \"file_type\": file_type,\n            \"session_id\": session_id,\n            \"extracted_at\": datetime.now().isoformat(),\n            \"raw_data\": raw_data,\n            \"enhanced_data\": enhanced\n        }\n</code></pre>"},{"location":"agent-workflow/#csv-extraction","title":"CSV Extraction","text":"<pre><code>def _read_csv(self, file_path: str) -&gt; Dict:\n    \"\"\"\n    Read CSV with pandas\n    \"\"\"\n    df = pd.read_csv(file_path)\n\n    return {\n        \"type\": \"csv\",\n        \"rows\": df.to_dict(orient='records'),\n        \"columns\": df.columns.tolist(),\n        \"row_count\": len(df)\n    }\n</code></pre>"},{"location":"agent-workflow/#pdf-extraction","title":"PDF Extraction","text":"<pre><code>def _read_pdf(self, file_path: str) -&gt; Dict:\n    \"\"\"\n    Extract text from PDF with pdfplumber\n    \"\"\"\n    with pdfplumber.open(file_path) as pdf:\n        text = \"\"\n        for page in pdf.pages:\n            text += page.extract_text() or \"\"\n\n    return {\n        \"type\": \"pdf\",\n        \"text\": text,\n        \"text_length\": len(text)\n    }\n</code></pre>"},{"location":"agent-workflow/#llm-enhancement","title":"LLM Enhancement","text":"<p>This is where the magic happens - the LLM analyzes the raw data:</p> <pre><code>def _enhance_with_llm(self, raw_data: Dict, file_type: str) -&gt; Dict:\n    \"\"\"\n    Use LLM to understand document structure and content\n    \"\"\"\n    # Build context for LLM\n    if raw_data[\"type\"] == \"csv\":\n        context = f\"CSV with columns: {raw_data['columns']}\\n\"\n        context += f\"Sample rows:\\n{json.dumps(raw_data['rows'][:5], indent=2)}\"\n    else:\n        context = raw_data[\"text\"][:3000]  # Limit context size\n\n    # Create analysis prompt\n    prompt = f\"\"\"[INST] Analyze this financial document and extract key information.\n\nIdentify:\n1. Document type (bank_statement, credit_card, invoice, budget, receipt, etc.)\n2. Date range or relevant dates (use YYYY-MM-DD format)\n3. Account information (if present)\n4. Currency (USD, EUR, etc.)\n5. Key financial entities present (transactions, balances, budgets, etc.)\n\nReturn ONLY valid JSON with these fields:\n{{\n    \"document_type\": \"type here\",\n    \"date_range\": \"range or single date\",\n    \"account_info\": \"account details or null\",\n    \"currency\": \"currency code\",\n    \"entities\": [\"list\", \"of\", \"entities\"]\n}}\n\nContext:\n{context}\n\n[/INST]\"\"\"\n\n    # Get LLM response\n    response = self.llm.generate(prompt, temperature=0.1)\n\n    try:\n        analysis = json.loads(response)\n        return {\"llm_analysis\": analysis}\n    except json.JSONDecodeError:\n        # Fallback if LLM doesn't return valid JSON\n        return {\"llm_analysis\": None, \"raw_response\": response}\n</code></pre>"},{"location":"agent-workflow/#output-format","title":"Output Format","text":"<p>output_1_{session_id}.json:</p> <pre><code>{\n  \"filename\": \"chase_statement.pdf\",\n  \"file_type\": \".pdf\",\n  \"session_id\": \"20251007_154523\",\n  \"extracted_at\": \"2025-10-07T15:45:23.123456\",\n  \"raw_data\": {\n    \"type\": \"pdf\",\n    \"text\": \"CHASE BANK Statement Period: 09/01/2025 - 09/30/2025...\",\n    \"text_length\": 5432\n  },\n  \"enhanced_data\": {\n    \"llm_analysis\": {\n      \"document_type\": \"bank_statement\",\n      \"date_range\": \"2025-09-01 to 2025-09-30\",\n      \"account_info\": \"Checking Account ****1234\",\n      \"currency\": \"USD\",\n      \"entities\": [\"transactions\", \"account_balance\"]\n    }\n  }\n}\n</code></pre>"},{"location":"agent-workflow/#agent-2-organizeragent","title":"Agent 2: OrganizerAgent \ud83d\udcca","text":""},{"location":"agent-workflow/#purpose_1","title":"Purpose","text":"<p>Convert unstructured extraction into structured, normalized data records.</p>"},{"location":"agent-workflow/#code-structure_1","title":"Code Structure","text":"<pre><code>class OrganizerAgent:\n    def __init__(self, llm_handler: LLMHandler):\n        self.llm = llm_handler\n\n    def organize(self, output_1_path: Path, session_id: str) -&gt; List[Path]:\n        \"\"\"\n        Create organized JSON files for each data type\n        \"\"\"\n        # Load extraction output\n        with open(output_1_path) as f:\n            data = json.load(f)\n\n        # Identify data types present\n        entities = data[\"enhanced_data\"][\"llm_analysis\"][\"entities\"]\n\n        organized_files = []\n        for entity in entities:\n            if entity == \"transactions\":\n                file_path = self._organize_transactions(data, session_id)\n                organized_files.append(file_path)\n            elif entity == \"budgets\":\n                file_path = self._organize_budgets(data, session_id)\n                organized_files.append(file_path)\n            # Add more entity types as needed\n\n        return organized_files\n</code></pre>"},{"location":"agent-workflow/#transaction-organization","title":"Transaction Organization","text":"<pre><code>def _organize_transactions(self, data: Dict, session_id: str) -&gt; Path:\n    \"\"\"\n    Extract and normalize transaction records\n    \"\"\"\n    # Get raw content\n    if data[\"raw_data\"][\"type\"] == \"csv\":\n        raw_content = json.dumps(data[\"raw_data\"][\"rows\"], indent=2)\n    else:\n        raw_content = data[\"raw_data\"][\"text\"][:4000]\n\n    # Create extraction prompt\n    prompt = f\"\"\"[INST] Extract ALL financial transactions from this document.\n\nFor each transaction, extract:\n- date: Transaction date in YYYY-MM-DD format\n- amount: Number (negative for expenses, positive for income)\n- description: What the transaction was for\n- category: Best guess category (Groceries, Dining, Transport, etc.)\n\nReturn ONLY valid JSON array:\n[\n    {{\"date\": \"2025-09-15\", \"amount\": -45.67, \"description\": \"Whole Foods\", \"category\": \"Groceries\"}},\n    {{\"date\": \"2025-09-16\", \"amount\": -12.50, \"description\": \"Coffee Shop\", \"category\": \"Dining\"}}\n]\n\nContext:\n{raw_content}\n\n[/INST]\"\"\"\n\n    # Get LLM response\n    response = self.llm.generate(prompt, temperature=0.1)\n\n    try:\n        transactions = json.loads(response)\n    except json.JSONDecodeError:\n        # Try to extract JSON from response\n        transactions = self._extract_json_array(response)\n\n    # Validate and normalize\n    transactions = self._validate_transactions(transactions)\n\n    # Build organized output\n    output = {\n        \"data_type\": \"transactions\",\n        \"records\": transactions,\n        \"metadata\": {\n            \"source_file\": data[\"filename\"],\n            \"extracted_at\": datetime.now().isoformat(),\n            \"record_count\": len(transactions),\n            \"session_id\": session_id\n        }\n    }\n\n    # Save to file\n    output_path = Path(\"data/temp\") / f\"organized_transactions_{session_id}.json\"\n    with open(output_path, 'w') as f:\n        json.dump(output, f, indent=2)\n\n    return output_path\n</code></pre>"},{"location":"agent-workflow/#validation","title":"Validation","text":"<pre><code>def _validate_transactions(self, transactions: List[Dict]) -&gt; List[Dict]:\n    \"\"\"\n    Ensure all transactions have required fields and valid values\n    \"\"\"\n    validated = []\n    for txn in transactions:\n        # Check required fields\n        if not all(k in txn for k in [\"date\", \"amount\", \"description\"]):\n            continue\n\n        # Normalize date\n        try:\n            # Try parsing various date formats\n            date = pd.to_datetime(txn[\"date\"]).strftime(\"%Y-%m-%d\")\n            txn[\"date\"] = date\n        except:\n            continue\n\n        # Ensure amount is numeric\n        try:\n            txn[\"amount\"] = float(txn[\"amount\"])\n        except:\n            continue\n\n        # Add default category if missing\n        if \"category\" not in txn or not txn[\"category\"]:\n            txn[\"category\"] = \"Uncategorized\"\n\n        validated.append(txn)\n\n    return validated\n</code></pre>"},{"location":"agent-workflow/#output-format_1","title":"Output Format","text":"<p>organized_transactions_{session_id}.json:</p> <pre><code>{\n  \"data_type\": \"transactions\",\n  \"records\": [\n    {\n      \"date\": \"2025-09-15\",\n      \"amount\": -45.67,\n      \"description\": \"Whole Foods Market #123\",\n      \"category\": \"Groceries\"\n    },\n    {\n      \"date\": \"2025-09-16\",\n      \"amount\": -12.50,\n      \"description\": \"Coffee Shop Downtown\",\n      \"category\": \"Dining\"\n    },\n    {\n      \"date\": \"2025-09-20\",\n      \"amount\": 3500.00,\n      \"description\": \"Salary Deposit\",\n      \"category\": \"Income\"\n    }\n  ],\n  \"metadata\": {\n    \"source_file\": \"chase_statement.pdf\",\n    \"extracted_at\": \"2025-10-07T15:45:25.654321\",\n    \"record_count\": 42,\n    \"session_id\": \"20251007_154523\"\n  }\n}\n</code></pre>"},{"location":"agent-workflow/#agent-3-databaseagent","title":"Agent 3: DatabaseAgent \ud83d\udcbe","text":""},{"location":"agent-workflow/#purpose_2","title":"Purpose","text":"<p>Dynamically manage database schema and write records transactionally.</p>"},{"location":"agent-workflow/#code-structure_2","title":"Code Structure","text":"<pre><code>class DatabaseAgent:\n    def __init__(self, llm_handler: LLMHandler):\n        self.llm = llm_handler\n\n    def write_to_db(self, organized_file_path: Path) -&gt; int:\n        \"\"\"\n        Write organized data to database with schema evolution\n        \"\"\"\n        # Load organized data\n        with open(organized_file_path) as f:\n            data = json.load(f)\n\n        data_type = data[\"data_type\"]\n        records = data[\"records\"]\n\n        if not records:\n            return 0\n\n        # Determine table name\n        table_name = data_type  # e.g., \"transactions\", \"budgets\"\n\n        # Step 1: Check if table exists\n        if not self._table_exists(table_name):\n            # Create new table based on first record\n            self._create_table(table_name, records[0])\n        else:\n            # Check if schema needs updating\n            self._update_schema_if_needed(table_name, records[0])\n\n        # Step 2: Insert all records\n        inserted = self._insert_records(table_name, records)\n\n        return inserted\n</code></pre>"},{"location":"agent-workflow/#table-creation","title":"Table Creation","text":"<pre><code>def _create_table(self, table_name: str, sample_record: Dict):\n    \"\"\"\n    Create table based on record structure\n    \"\"\"\n    # Infer column types from sample record\n    columns = []\n    for key, value in sample_record.items():\n        sql_type = self._infer_sql_type(value)\n        columns.append(f\"{key} {sql_type}\")\n\n    # Add metadata columns\n    columns.append(\"created_at TEXT DEFAULT CURRENT_TIMESTAMP\")\n    columns.append(\"updated_at TEXT DEFAULT CURRENT_TIMESTAMP\")\n\n    # Build CREATE TABLE statement\n    columns_sql = \", \".join(columns)\n    create_sql = f\"\"\"\n    CREATE TABLE IF NOT EXISTS {table_name} (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        {columns_sql}\n    )\n    \"\"\"\n\n    # Execute\n    conn = sqlite3.connect(\"data/finance.db\")\n    try:\n        conn.execute(create_sql)\n        conn.commit()\n    finally:\n        conn.close()\n</code></pre>"},{"location":"agent-workflow/#schema-evolution","title":"Schema Evolution","text":"<pre><code>def _update_schema_if_needed(self, table_name: str, sample_record: Dict):\n    \"\"\"\n    Add new columns if record has fields not in table\n    \"\"\"\n    conn = sqlite3.connect(\"data/finance.db\")\n    try:\n        # Get existing columns\n        cursor = conn.execute(f\"PRAGMA table_info({table_name})\")\n        existing_cols = {row[1] for row in cursor.fetchall()}\n\n        # Find new columns\n        record_cols = set(sample_record.keys())\n        new_cols = record_cols - existing_cols\n\n        # Add new columns\n        for col in new_cols:\n            sql_type = self._infer_sql_type(sample_record[col])\n            alter_sql = f\"ALTER TABLE {table_name} ADD COLUMN {col} {sql_type}\"\n            conn.execute(alter_sql)\n\n        if new_cols:\n            conn.commit()\n    finally:\n        conn.close()\n</code></pre>"},{"location":"agent-workflow/#type-inference","title":"Type Inference","text":"<pre><code>def _infer_sql_type(self, value) -&gt; str:\n    \"\"\"\n    Infer SQL type from Python value\n    \"\"\"\n    if isinstance(value, bool):\n        return \"INTEGER\"  # SQLite uses INTEGER for booleans\n    elif isinstance(value, int):\n        return \"INTEGER\"\n    elif isinstance(value, float):\n        return \"REAL\"\n    elif isinstance(value, (dict, list)):\n        return \"TEXT\"  # Store as JSON string\n    else:\n        return \"TEXT\"\n</code></pre>"},{"location":"agent-workflow/#record-insertion","title":"Record Insertion","text":"<pre><code>def _insert_records(self, table_name: str, records: List[Dict]) -&gt; int:\n    \"\"\"\n    Insert records with transaction safety\n    \"\"\"\n    conn = sqlite3.connect(\"data/finance.db\")\n    try:\n        conn.execute(\"BEGIN TRANSACTION\")\n\n        inserted = 0\n        for record in records:\n            # Build INSERT statement\n            columns = list(record.keys())\n            placeholders = \", \".join(\"?\" * len(columns))\n            columns_sql = \", \".join(columns)\n            values = [record[col] for col in columns]\n\n            insert_sql = f\"\"\"\n            INSERT INTO {table_name} ({columns_sql})\n            VALUES ({placeholders})\n            \"\"\"\n\n            conn.execute(insert_sql, values)\n            inserted += 1\n\n        conn.commit()\n        return inserted\n    except Exception as e:\n        conn.rollback()\n        raise e\n    finally:\n        conn.close()\n</code></pre>"},{"location":"agent-workflow/#cleanup-lifecycle","title":"Cleanup &amp; Lifecycle","text":""},{"location":"agent-workflow/#session-cleanup","title":"Session Cleanup","text":"<pre><code>def _cleanup_session(self, session_id: str):\n    \"\"\"\n    Delete all temporary files for this session\n    \"\"\"\n    temp_dir = Path(\"data/temp\")\n\n    # Find all files for this session\n    session_files = list(temp_dir.glob(f\"*{session_id}*\"))\n\n    for file_path in session_files:\n        try:\n            file_path.unlink()\n        except Exception as e:\n            print(f\"Warning: Could not delete {file_path}: {e}\")\n</code></pre>"},{"location":"agent-workflow/#error-handling","title":"Error Handling","text":"<pre><code>graph TD\n    A[Start Process] --&gt; B{LLM Available?}\n    B --&gt;|No| C[Return Error]\n    B --&gt;|Yes| D[Agent 1: Extract]\n\n    D --&gt; E{Success?}\n    E --&gt;|No| F[Return Error]\n    E --&gt;|Yes| G[Agent 2: Organize]\n\n    G --&gt; H{Success?}\n    H --&gt;|No| I[Cleanup + Return Error]\n    H --&gt;|Yes| J[Agent 3: Database]\n\n    J --&gt; K{Success?}\n    K --&gt;|No| L[Rollback + Cleanup + Error]\n    K --&gt;|Yes| M[Cleanup + Success]\n\n    style C fill:#ffcdd2\n    style F fill:#ffcdd2\n    style I fill:#ffcdd2\n    style L fill:#ffcdd2\n    style M fill:#c8e6c9</code></pre>"},{"location":"agent-workflow/#performance-optimization","title":"Performance Optimization","text":""},{"location":"agent-workflow/#caching-strategy","title":"Caching Strategy","text":"<pre><code>class LLMHandler:\n    def __init__(self):\n        # Model stays in memory after first load\n        self.llm = Llama(\n            model_path=str(self.model_path),\n            n_ctx=4096,\n            n_threads=4,\n            verbose=False\n        )\n</code></pre>"},{"location":"agent-workflow/#batch-processing","title":"Batch Processing","text":"<p>For multiple files:</p> <pre><code>def process_batch(self, file_paths: List[str]) -&gt; List[Dict]:\n    \"\"\"\n    Process multiple files efficiently\n    \"\"\"\n    results = []\n\n    # Model loads once at initialization\n    for file_path in file_paths:\n        result = self.process_file(file_path)\n        results.append(result)\n\n    return results\n</code></pre>"},{"location":"agent-workflow/#token-limits","title":"Token Limits","text":"<pre><code># Context truncation to avoid token limits\ncontext = raw_text[:3000]  # ~750 tokens\n</code></pre>"},{"location":"agent-workflow/#testing","title":"Testing","text":""},{"location":"agent-workflow/#unit-tests","title":"Unit Tests","text":"<pre><code>def test_extraction_agent():\n    llm = LLMHandler()\n    agent = ExtractionAgent(llm)\n\n    result = agent.extract(\"test_statement.csv\", \"statement.csv\", \"test_session\")\n\n    assert \"raw_data\" in result\n    assert \"enhanced_data\" in result\n    assert result[\"file_type\"] == \".csv\"\n</code></pre>"},{"location":"agent-workflow/#integration-tests","title":"Integration Tests","text":"<pre><code>def test_full_workflow():\n    workflow = AgentWorkflow()\n\n    result = workflow.process_file(\"test_files/sample.pdf\", \"sample.pdf\")\n\n    assert result[\"success\"] == True\n    assert result[\"records\"] &gt; 0\n\n    # Check database\n    conn = sqlite3.connect(\"data/finance.db\")\n    cursor = conn.execute(\"SELECT COUNT(*) FROM transactions\")\n    count = cursor.fetchone()[0]\n    assert count &gt; 0\n</code></pre>"},{"location":"agent-workflow/#next-steps","title":"Next Steps","text":"<ul> <li>Data Flow Diagrams - Visual data flow</li> <li>Database Schema - Schema details</li> <li>LLM Integration - Working with the LLM</li> </ul> <p>Debugging Tips</p> <ul> <li>Check <code>data/temp/</code> for intermediate JSON files</li> <li>Look for <code>output_1_*.json</code> and <code>organized_*.json</code></li> <li>SQLite browser to inspect database directly</li> <li>Set <code>verbose=True</code> in LLMHandler for detailed logs</li> </ul>"},{"location":"ai-architecture/","title":"AI-First Architecture","text":"<p>Finance AI Dashboard is built with an AI-first philosophy. This means the AI is not an optional enhancement - it's the core of the application.</p>"},{"location":"ai-architecture/#philosophy","title":"Philosophy","text":""},{"location":"ai-architecture/#traditional-vs-ai-first","title":"Traditional vs AI-First","text":"<pre><code>graph TB\n    subgraph \"Traditional Approach\"\n        A1[Upload CSV] --&gt; B1[Rigid Parser]\n        B1 --&gt; C1[Pattern Matching]\n        C1 --&gt; D1[Static Database]\n        D1 --&gt; E1[Limited Results]\n    end\n\n    subgraph \"AI-First Approach\"\n        A2[Upload ANY File] --&gt; B2[AI Understanding]\n        B2 --&gt; C2[Context Analysis]\n        C2 --&gt; D2[Dynamic Schema]\n        D2 --&gt; E2[Rich Results]\n    end\n\n    style B2 fill:#e1f5ff\n    style C2 fill:#e8f5e9\n    style D2 fill:#fff3e0</code></pre>"},{"location":"ai-architecture/#why-ai-first-matters","title":"Why AI-First Matters","text":"<p>Traditional Approach Problems:</p> <ul> <li>\u274c Only works with perfectly formatted files</li> <li>\u274c Breaks with new formats</li> <li>\u274c Requires manual data entry for unstructured documents</li> <li>\u274c Can't understand context</li> <li>\u274c Limited to predefined categories</li> </ul> <p>AI-First Benefits:</p> <ul> <li>\u2705 Handles any document format</li> <li>\u2705 Adapts to new layouts automatically</li> <li>\u2705 Extracts from text, tables, and images (OCR)</li> <li>\u2705 Understands context and intent</li> <li>\u2705 Creates new categories dynamically</li> </ul>"},{"location":"ai-architecture/#core-components","title":"Core Components","text":""},{"location":"ai-architecture/#1-local-llm-engine","title":"1. Local LLM Engine","text":"<p>Finance AI uses Mistral-7B-Instruct, a powerful open-source language model running entirely on your machine.</p> <pre><code>graph LR\n    A[Document] --&gt; B[LLM Engine]\n    B --&gt; C[Understanding]\n    C --&gt; D[Structured Data]\n\n    subgraph \"LLM Engine\"\n        B1[Mistral-7B] --&gt; B2[4.7GB Model]\n        B2 --&gt; B3[llama.cpp Runtime]\n    end\n\n    style B fill:#f3e5f5</code></pre> <p>Specifications:</p> Property Value Model Mistral-7B-Instruct-v0.1 Quantization Q5_0 (~4.7GB) Context Window 4096 tokens Runtime llama-cpp-python Speed 5-10 tokens/sec (CPU) Privacy 100% offline <p>Why Mistral-7B?</p> <ul> <li>\u2705 Excellent instruction following</li> <li>\u2705 Good balance of size vs capability</li> <li>\u2705 Optimized for CPU efficiency</li> <li>\u2705 Free and open source</li> <li>\u2705 Works well for financial data</li> </ul>"},{"location":"ai-architecture/#2-three-specialized-agents","title":"2. Three Specialized Agents","text":"<p>Each agent has a specific role and uses the LLM differently:</p> <pre><code>graph TB\n    subgraph \"Agent 1: Extractor\"\n        A1[Read File] --&gt; A2{Document Type?}\n        A2 --&gt;|CSV| A3[Parse Structure]\n        A2 --&gt;|PDF| A4[Extract Text]\n        A2 --&gt;|Text| A5[Read Content]\n        A3 --&gt; A6[LLM Analysis]\n        A4 --&gt; A6\n        A5 --&gt; A6\n        A6 --&gt; A7[output_1.json]\n    end\n\n    subgraph \"Agent 2: Organizer\"\n        B1[Read output_1] --&gt; B2{Identify Types}\n        B2 --&gt;|Transactions| B3[Extract Rows]\n        B2 --&gt;|Budgets| B4[Extract Plans]\n        B2 --&gt;|Accounts| B5[Extract Info]\n        B3 --&gt; B6[LLM Structure]\n        B4 --&gt; B6\n        B5 --&gt; B6\n        B6 --&gt; B7[organized_*.json]\n    end\n\n    subgraph \"Agent 3: Database\"\n        C1[Read organized] --&gt; C2{Table Exists?}\n        C2 --&gt;|No| C3[Create Table]\n        C2 --&gt;|Yes| C4{Columns Match?}\n        C4 --&gt;|No| C5[Add Columns]\n        C3 --&gt; C6[Write Records]\n        C4 --&gt;|Yes| C6\n        C5 --&gt; C6\n        C6 --&gt; C7[(SQLite DB)]\n    end\n\n    A7 --&gt; B1\n    B7 --&gt; C1\n\n    style A6 fill:#e1f5ff\n    style B6 fill:#e8f5e9\n    style C7 fill:#fff3e0</code></pre>"},{"location":"ai-architecture/#agent-details","title":"Agent Details","text":""},{"location":"ai-architecture/#agent-1-extraction-agent","title":"Agent 1: Extraction Agent \ud83d\udd0d","text":"<p>Purpose: Universal document reader and context analyzer</p> <p>Intelligence Level: High - Must understand diverse document formats</p> <p>AI Tasks:</p> <ol> <li>Identify document type (bank statement, invoice, budget, receipt, etc.)</li> <li>Extract relevant financial entities</li> <li>Understand date ranges, currencies, account information</li> <li>Handle both structured and unstructured data</li> </ol> <p>Example LLM Prompt:</p> <pre><code>prompt = \"\"\"\nAnalyze this financial document and extract key information.\n\nIdentify:\n1. Document type (bank statement, credit card, invoice, budget, etc.)\n2. Date range or relevant dates\n3. Account information (if present)\n4. Currency\n5. Key financial entities (transactions, balances, totals)\n\nReturn as JSON.\n\nContext:\n[document content here...]\n\"\"\"\n</code></pre> <p>Output Structure:</p> <pre><code>{\n  \"filename\": \"statement.pdf\",\n  \"file_type\": \".pdf\",\n  \"session_id\": \"20251007_154523\",\n  \"extracted_at\": \"2025-10-07T15:45:23.123456\",\n  \"raw_data\": {\n    \"type\": \"pdf\",\n    \"text\": \"...\",\n    \"text_length\": 5432\n  },\n  \"enhanced_data\": {\n    \"llm_analysis\": {\n      \"document_type\": \"bank_statement\",\n      \"date_range\": \"2025-09-01 to 2025-09-30\",\n      \"account_info\": \"Checking ****1234\",\n      \"currency\": \"USD\",\n      \"entities\": [\"transactions\", \"balances\"]\n    }\n  }\n}\n</code></pre>"},{"location":"ai-architecture/#agent-2-organizer-agent","title":"Agent 2: Organizer Agent \ud83d\udcca","text":"<p>Purpose: Intelligent data structuring and normalization</p> <p>Intelligence Level: Very High - Must structure unstructured data</p> <p>AI Tasks:</p> <ol> <li>Identify what types of data are present</li> <li>Extract structured records from unstructured text</li> <li>Normalize data to standard formats</li> <li>Determine appropriate categories and fields</li> </ol> <p>Example LLM Prompt:</p> <pre><code>prompt = \"\"\"\nExtract all financial transactions from this text.\n\nFor each transaction, identify:\n- date (in YYYY-MM-DD format if possible)\n- amount (as a number, negative for expenses, positive for income)\n- description (what the transaction was for)\n\nReturn as JSON array: [{\"date\": \"...\", \"amount\": 0.0, \"description\": \"...\"}]\n\nContext:\n[transaction data here...]\n\"\"\"\n</code></pre> <p>Output Structure:</p> <pre><code>{\n  \"data_type\": \"transactions\",\n  \"records\": [\n    {\n      \"date\": \"2025-09-15\",\n      \"amount\": -45.67,\n      \"description\": \"Whole Foods Market #123\",\n      \"category\": \"Groceries\"\n    },\n    {\n      \"date\": \"2025-09-16\",\n      \"amount\": -12.50,\n      \"description\": \"Coffee Shop Downtown\",\n      \"category\": \"Dining\"\n    }\n  ],\n  \"metadata\": {\n    \"source_file\": \"statement.pdf\",\n    \"extracted_at\": \"2025-10-07T15:45:25\",\n    \"record_count\": 42\n  }\n}\n</code></pre>"},{"location":"ai-architecture/#agent-3-database-agent","title":"Agent 3: Database Agent \ud83d\udcbe","text":"<p>Purpose: Dynamic schema management and data persistence</p> <p>Intelligence Level: Medium - Primarily rule-based with inference</p> <p>AI Tasks:</p> <ol> <li>Analyze data structure from organized JSONs</li> <li>Determine if new tables are needed</li> <li>Identify missing columns in existing tables</li> <li>Infer appropriate SQL types from Python values</li> <li>Write data transactionally</li> </ol> <p>Schema Evolution Example:</p> <pre><code>graph TB\n    A[Receive organized_budgets.json] --&gt; B{budgets table exists?}\n    B --&gt;|No| C[Infer Schema]\n    B --&gt;|Yes| D[Get Existing Columns]\n    C --&gt; E[CREATE TABLE budgets]\n    D --&gt; F{New fields present?}\n    F --&gt;|Yes| G[ALTER TABLE ADD COLUMN]\n    F --&gt;|No| H[Use Existing Schema]\n    E --&gt; I[Write Records]\n    G --&gt; I\n    H --&gt; I\n    I --&gt; J[(Database Updated)]\n\n    style C fill:#fff3e0\n    style E fill:#fff3e0\n    style G fill:#ffecb3</code></pre> <p>Type Inference:</p> <pre><code>def infer_sql_type(value):\n    if isinstance(value, bool):\n        return \"INTEGER\"  # SQLite uses INTEGER for boolean\n    elif isinstance(value, int):\n        return \"INTEGER\"\n    elif isinstance(value, float):\n        return \"REAL\"\n    else:\n        return \"TEXT\"\n</code></pre>"},{"location":"ai-architecture/#complete-workflow","title":"Complete Workflow","text":""},{"location":"ai-architecture/#end-to-end-processing","title":"End-to-End Processing","text":"<pre><code>sequenceDiagram\n    participant U as User\n    participant UI as Dashboard\n    participant A1 as Agent 1\n    participant LLM as Mistral LLM\n    participant A2 as Agent 2\n    participant A3 as Agent 3\n    participant DB as SQLite DB\n\n    U-&gt;&gt;UI: Upload statement.pdf\n    UI-&gt;&gt;A1: Process file\n\n    Note over A1: Extraction Phase\n    A1-&gt;&gt;A1: Extract PDF text\n    A1-&gt;&gt;LLM: Analyze document type\n    LLM--&gt;&gt;A1: \"bank_statement\"\n    A1-&gt;&gt;LLM: Extract entities\n    LLM--&gt;&gt;A1: Structured data\n    A1-&gt;&gt;A1: Save output_1.json\n\n    Note over A2: Organization Phase\n    A1-&gt;&gt;A2: output_1.json\n    A2-&gt;&gt;A2: Identify data types\n    A2-&gt;&gt;LLM: Extract transactions\n    LLM--&gt;&gt;A2: Transaction array\n    A2-&gt;&gt;A2: Normalize &amp; validate\n    A2-&gt;&gt;A2: Save organized_transactions.json\n\n    Note over A3: Database Phase\n    A2-&gt;&gt;A3: organized_transactions.json\n    A3-&gt;&gt;DB: Check schema\n    DB--&gt;&gt;A3: Schema info\n    A3-&gt;&gt;DB: CREATE/ALTER if needed\n    A3-&gt;&gt;DB: INSERT records\n    DB--&gt;&gt;A3: Success\n\n    Note over A3: Cleanup\n    A3-&gt;&gt;A3: Delete temp files\n\n    A3-&gt;&gt;UI: Success: 42 records\n    UI-&gt;&gt;U: \u2713 statement.pdf: 42 records processed \ud83e\udd16</code></pre>"},{"location":"ai-architecture/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"ai-architecture/#processing-speed","title":"Processing Speed","text":"<pre><code>graph LR\n    A[First Upload&lt;br/&gt;7-15 sec] --&gt; B[Model Load&lt;br/&gt;5-10 sec]\n    A --&gt; C[Processing&lt;br/&gt;2-5 sec]\n\n    D[Subsequent&lt;br/&gt;2-5 sec] --&gt; E[Model Cached&lt;br/&gt;0 sec]\n    D --&gt; F[Processing&lt;br/&gt;2-5 sec]\n\n    style A fill:#ffcdd2\n    style D fill:#c8e6c9</code></pre> <p>Breakdown:</p> Phase First Upload Cached Model Loading 5-10 sec 0 sec Agent 1 (Extract) 1-2 sec 1-2 sec Agent 2 (Organize) 1-2 sec 1-2 sec Agent 3 (Database) &lt;1 sec &lt;1 sec Total 7-15 sec 2-5 sec"},{"location":"ai-architecture/#memory-usage","title":"Memory Usage","text":"<pre><code>pie title \"Memory Distribution (Total ~5GB)\"\n    \"LLM Model\" : 4700\n    \"Python Runtime\" : 200\n    \"Processing Buffer\" : 100</code></pre>"},{"location":"ai-architecture/#prompt-engineering","title":"Prompt Engineering","text":""},{"location":"ai-architecture/#key-principles","title":"Key Principles","text":"<p>Finance AI uses carefully crafted prompts to get reliable results from the LLM:</p> <ol> <li>Clear Instructions: Tell the LLM exactly what to extract</li> <li>JSON Output: Always request structured JSON responses</li> <li>Context Limits: Truncate input to ~3000 tokens</li> <li>Low Temperature: Use 0.1 for deterministic financial data</li> <li>Examples: Provide format examples in prompts</li> </ol>"},{"location":"ai-architecture/#prompt-template","title":"Prompt Template","text":"<pre><code>def create_extraction_prompt(instruction, context):\n    return f\"\"\"[INST] {instruction}\n\nYou must respond with valid JSON only. Do not include any explanation.\n\nContext:\n{context[:3000]}\n\n[/INST]\"\"\"\n</code></pre>"},{"location":"ai-architecture/#temperature-settings","title":"Temperature Settings","text":"<pre><code># For financial data (use low temperature for consistency)\nllm.generate(prompt, temperature=0.1)  # Deterministic\n\n# For creative tasks (if needed)\nllm.generate(prompt, temperature=0.7)  # More varied\n</code></pre>"},{"location":"ai-architecture/#fallback-strategies","title":"Fallback Strategies","text":"<p>While AI-first, the system has intelligent fallbacks:</p> <pre><code>graph TD\n    A[Start Processing] --&gt; B{LLM Available?}\n    B --&gt;|Yes| C[Use AI Extraction]\n    B --&gt;|No| D[Show Error]\n\n    C --&gt; E{Got Results?}\n    E --&gt;|Yes| F[Continue Pipeline]\n    E --&gt;|No| G[Try Pattern Matching]\n\n    G --&gt; H{Got Results?}\n    H --&gt;|Yes| F\n    H --&gt;|No| I[Manual Entry Prompt]\n\n    style C fill:#c8e6c9\n    style D fill:#ffcdd2\n    style G fill:#fff9c4</code></pre>"},{"location":"ai-architecture/#why-this-works","title":"Why This Works","text":""},{"location":"ai-architecture/#1-flexibility","title":"1. Flexibility","text":"<p>LLMs can understand almost any document format. New bank? New layout? No problem.</p> <p>Example: <pre><code>Input: \"WHOLEFDS #123 09/15 -45.67\"\nLLM Output: {\n  \"date\": \"2025-09-15\",\n  \"amount\": -45.67,\n  \"description\": \"Whole Foods Market #123\",\n  \"category\": \"Groceries\"\n}\n</code></pre></p>"},{"location":"ai-architecture/#2-context-understanding","title":"2. Context Understanding","text":"<p>The LLM doesn't just match keywords - it understands meaning:</p> <ul> <li>\"WHOLEFDS\" \u2192 Whole Foods \u2192 Groceries (not just keyword matching)</li> <li>\"SPOTIFY PREMIUM\" \u2192 Subscription (understands it's recurring)</li> <li>\"Interest Earned\" \u2192 Income (understands credit vs debit)</li> </ul>"},{"location":"ai-architecture/#3-future-proof","title":"3. Future-Proof","text":"<p>As LLMs improve, so does the app. Just swap the model file:</p> <pre><code># Upgrade to a better model\nwget newer-better-model.gguf\n# Update llm_handler.py to point to new model\n</code></pre>"},{"location":"ai-architecture/#4-self-improving","title":"4. Self-Improving","text":"<p>User corrections can be fed back to improve categorization over time (via the <code>mem_labels</code> table).</p>"},{"location":"ai-architecture/#model-alternatives","title":"Model Alternatives","text":"<p>Different models for different needs:</p>"},{"location":"ai-architecture/#smaller-faster-less-capable","title":"Smaller (Faster, Less Capable)","text":"<ul> <li>TinyLlama-1.1B: ~600MB, 3x faster, good for simple documents</li> <li>Phi-2-2.7B: ~1.5GB, 2x faster, decent accuracy</li> </ul>"},{"location":"ai-architecture/#larger-slower-more-capable","title":"Larger (Slower, More Capable)","text":"<ul> <li>Mistral-7B-Q8: ~7GB, more accurate, slower</li> <li>Llama-2-13B: ~13GB, best quality, requires 16GB+ RAM</li> </ul>"},{"location":"ai-architecture/#how-to-swap","title":"How to Swap","text":"<pre><code># In llm_handler.py\nmodel_path = Path(\"your-model-name.gguf\")\n</code></pre>"},{"location":"ai-architecture/#privacy-security","title":"Privacy &amp; Security","text":"<pre><code>graph LR\n    A[Your Files] --&gt; B[Your RAM]\n    B --&gt; C[Your Database]\n\n    B -.-&gt;|Never| D[\u274c Cloud]\n    B -.-&gt;|Never| E[\u274c APIs]\n    B -.-&gt;|Never| F[\u274c Internet]\n\n    style D fill:#ffcdd2\n    style E fill:#ffcdd2\n    style F fill:#ffcdd2</code></pre> <p>Data Flow: <pre><code>Your Files \u2192 Your RAM \u2192 Your Database\n           \u2191\n    Never leaves your machine\n</code></pre></p>"},{"location":"ai-architecture/#next-steps","title":"Next Steps","text":"<ul> <li>Agent Workflow Details - Technical deep dive</li> <li>LLM Integration - How to work with the LLM</li> <li>Database Schema - Dynamic schema details</li> </ul> <p>AI-First Philosophy</p> <p>\"The AI is not a feature. The AI IS the product.\"</p>"},{"location":"database-schema/","title":"Database Schema","text":"<p>Finance AI uses SQLite with dynamic schema evolution, meaning tables and columns are created automatically based on your data.</p>"},{"location":"database-schema/#core-concept","title":"Core Concept","text":"<p>Unlike traditional databases with fixed schemas, Finance AI adapts:</p> <pre><code>graph LR\n    A[New Data Type] --&gt; B{Table Exists?}\n    B --&gt;|No| C[Create Table]\n    B --&gt;|Yes| D{Columns Match?}\n    D --&gt;|No| E[Add Columns]\n    D --&gt;|Yes| F[Insert Data]\n    C --&gt; F\n    E --&gt; F\n\n    style C fill:#fff3e0\n    style E fill:#ffecb3</code></pre>"},{"location":"database-schema/#database-location","title":"Database Location","text":"<pre><code>data/finance.db\n</code></pre> <p>Type: SQLite3 Size: Grows with your data (~1KB per transaction)</p>"},{"location":"database-schema/#default-tables","title":"Default Tables","text":""},{"location":"database-schema/#transactions","title":"transactions","text":"<p>Stores all financial transactions from uploaded files.</p> <p>Schema:</p> Column Type Description <code>id</code> INTEGER Primary key (auto-increment) <code>date</code> TEXT Transaction date (YYYY-MM-DD) <code>amount</code> REAL Amount (negative = expense, positive = income) <code>description</code> TEXT What the transaction was for <code>category</code> TEXT Category (e.g., \"Groceries\", \"Dining\") <code>created_at</code> TEXT When record was created (timestamp) <code>updated_at</code> TEXT Last update timestamp <p>Example Records:</p> <pre><code>sqlite&gt; SELECT * FROM transactions LIMIT 3;\n\nid  date        amount   description              category   created_at           updated_at\n--  ----------  -------  ----------------------  ---------  ------------------  ------------------\n1   2025-01-15  -45.67   Whole Foods Market #123  Groceries  2025-10-07 15:45:23  2025-10-07 15:45:23\n2   2025-01-16  -5.25    Starbucks Coffee Shop    Dining     2025-10-07 15:45:23  2025-10-07 15:45:23\n3   2025-01-25  3500.00  Salary Deposit          Income     2025-10-07 15:45:23  2025-10-07 15:45:23\n</code></pre> <p>Create Statement:</p> <pre><code>CREATE TABLE IF NOT EXISTS transactions (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    date TEXT,\n    amount REAL,\n    description TEXT,\n    category TEXT,\n    created_at TEXT DEFAULT CURRENT_TIMESTAMP,\n    updated_at TEXT DEFAULT CURRENT_TIMESTAMP\n);\n</code></pre>"},{"location":"database-schema/#mem_labels","title":"mem_labels","text":"<p>Stores learned keyword-to-category mappings for improving future categorization.</p> <p>Schema:</p> Column Type Description <code>id</code> INTEGER Primary key <code>keyword</code> TEXT Keyword or phrase (e.g., \"whole foods\") <code>category</code> TEXT Assigned category (e.g., \"Groceries\") <code>created_at</code> TEXT When mapping was created <p>Example Records:</p> <pre><code>sqlite&gt; SELECT * FROM mem_labels;\n\nid  keyword         category    created_at\n--  -------------  ----------  ------------------\n1   whole foods     Groceries   2025-10-07 16:20:15\n2   starbucks       Dining      2025-10-07 16:21:30\n3   shell gas       Transport   2025-10-07 16:22:45\n4   amazon          Shopping    2025-10-07 16:23:10\n</code></pre> <p>Create Statement:</p> <pre><code>CREATE TABLE IF NOT EXISTS mem_labels (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    keyword TEXT UNIQUE,\n    category TEXT,\n    created_at TEXT DEFAULT CURRENT_TIMESTAMP\n);\n</code></pre> <p>Purpose:</p> <p>When you manually change a transaction category, the system remembers:</p> <ol> <li>User changes \"WHOLEFDS #123\" from \"Uncategorized\" to \"Groceries\"</li> <li>System extracts keyword: \"wholefds\" or \"whole foods\"</li> <li>Stores mapping: <code>whole foods \u2192 Groceries</code></li> <li>Future transactions with \"Whole Foods\" auto-categorize to \"Groceries\"</li> </ol>"},{"location":"database-schema/#documents_metadata-optional","title":"documents_metadata (Optional)","text":"<p>If you want to track uploaded files:</p> <p>Schema:</p> Column Type Description <code>id</code> INTEGER Primary key <code>filename</code> TEXT Original filename <code>file_type</code> TEXT Extension (.csv, .pdf, .txt) <code>file_size</code> INTEGER Size in bytes <code>upload_date</code> TEXT When file was uploaded <code>records_extracted</code> INTEGER Number of records extracted <code>session_id</code> TEXT Processing session ID <p>Example:</p> <pre><code>sqlite&gt; SELECT * FROM documents_metadata;\n\nid  filename           file_type  file_size  upload_date          records_extracted  session_id\n--  ----------------  ---------  ---------  -------------------  -----------------  --------------\n1   chase_jan.csv      .csv       12543      2025-10-07 15:45:20  42                 20251007_154520\n2   amex_jan.pdf       .pdf       234567     2025-10-07 16:10:15  38                 20251007_161015\n</code></pre>"},{"location":"database-schema/#dynamic-schema-evolution","title":"Dynamic Schema Evolution","text":""},{"location":"database-schema/#how-it-works","title":"How It Works","text":"<p>When Agent 3 (DatabaseAgent) receives organized data:</p> <pre><code>graph TD\n    A[Receive organized_budgets.json] --&gt; B{budgets table exists?}\n    B --&gt;|No| C[Analyze First Record]\n    B --&gt;|Yes| D[Get Existing Schema]\n\n    C --&gt; E[Infer Column Types]\n    E --&gt; F[CREATE TABLE budgets]\n\n    D --&gt; G{New Fields Present?}\n    G --&gt;|Yes| H[Infer New Column Types]\n    G --&gt;|No| I[Use Existing Schema]\n    H --&gt; J[ALTER TABLE ADD COLUMN]\n\n    F --&gt; K[INSERT Records]\n    I --&gt; K\n    J --&gt; K\n\n    style C fill:#fff3e0\n    style E fill:#fff3e0\n    style H fill:#ffecb3</code></pre>"},{"location":"database-schema/#example-new-table-creation","title":"Example: New Table Creation","text":"<p>Input: <code>organized_budgets.json</code></p> <pre><code>{\n  \"data_type\": \"budgets\",\n  \"records\": [\n    {\n      \"month\": \"2025-01\",\n      \"category\": \"Groceries\",\n      \"planned\": 500.00,\n      \"actual\": 467.89,\n      \"remaining\": 32.11\n    }\n  ]\n}\n</code></pre> <p>Agent 3 Actions:</p> <ol> <li>Check if <code>budgets</code> table exists \u2192 No</li> <li>Analyze first record \u2192 Infer types:</li> <li><code>month</code> (TEXT)</li> <li><code>category</code> (TEXT)</li> <li><code>planned</code> (REAL)</li> <li><code>actual</code> (REAL)</li> <li><code>remaining</code> (REAL)</li> <li>Create table:</li> </ol> <pre><code>CREATE TABLE budgets (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    month TEXT,\n    category TEXT,\n    planned REAL,\n    actual REAL,\n    remaining REAL,\n    created_at TEXT DEFAULT CURRENT_TIMESTAMP,\n    updated_at TEXT DEFAULT CURRENT_TIMESTAMP\n);\n</code></pre> <ol> <li>Insert record</li> </ol>"},{"location":"database-schema/#example-schema-extension","title":"Example: Schema Extension","text":"<p>Scenario: You upload a new budget file with an extra field</p> <p>New Input: <code>organized_budgets.json</code></p> <pre><code>{\n  \"data_type\": \"budgets\",\n  \"records\": [\n    {\n      \"month\": \"2025-02\",\n      \"category\": \"Groceries\",\n      \"planned\": 500.00,\n      \"actual\": 445.23,\n      \"remaining\": 54.77,\n      \"notes\": \"Saved by shopping sales\"  // NEW FIELD\n    }\n  ]\n}\n</code></pre> <p>Agent 3 Actions:</p> <ol> <li>Check if <code>budgets</code> table exists \u2192 Yes</li> <li>Get existing columns \u2192 <code>[month, category, planned, actual, remaining]</code></li> <li>Detect new field \u2192 <code>notes</code></li> <li>Infer type \u2192 <code>TEXT</code></li> <li>Alter table:</li> </ol> <pre><code>ALTER TABLE budgets ADD COLUMN notes TEXT;\n</code></pre> <ol> <li>Insert record (including new field)</li> </ol>"},{"location":"database-schema/#type-inference","title":"Type Inference","text":"<pre><code>def infer_sql_type(value):\n    if isinstance(value, bool):\n        return \"INTEGER\"  # SQLite uses 0/1 for boolean\n    elif isinstance(value, int):\n        return \"INTEGER\"\n    elif isinstance(value, float):\n        return \"REAL\"\n    elif isinstance(value, (dict, list)):\n        return \"TEXT\"  # Stored as JSON string\n    else:\n        return \"TEXT\"  # Default\n</code></pre> <p>Type Mappings:</p> Python Type SQL Type Example <code>bool</code> INTEGER <code>True \u2192 1</code>, <code>False \u2192 0</code> <code>int</code> INTEGER <code>42</code>, <code>-100</code> <code>float</code> REAL <code>45.67</code>, <code>3500.00</code> <code>str</code> TEXT <code>\"Groceries\"</code>, <code>\"2025-01-15\"</code> <code>dict</code>, <code>list</code> TEXT Stored as JSON string <code>None</code> NULL NULL value"},{"location":"database-schema/#querying-the-database","title":"Querying the Database","text":""},{"location":"database-schema/#using-sqlite-cli","title":"Using SQLite CLI","text":"<pre><code># Open database\nsqlite3 data/finance.db\n\n# List tables\n.tables\n\n# View schema\n.schema transactions\n\n# Query transactions\nSELECT * FROM transactions WHERE category = 'Groceries';\n\n# Aggregations\nSELECT category, SUM(amount) as total \nFROM transactions \nWHERE amount &lt; 0 \nGROUP BY category\nORDER BY total;\n</code></pre>"},{"location":"database-schema/#using-python","title":"Using Python","text":"<pre><code>import sqlite3\nimport pandas as pd\n\n# Connect\nconn = sqlite3.connect('data/finance.db')\n\n# Query as DataFrame\ndf = pd.read_sql_query(\"SELECT * FROM transactions\", conn)\n\n# Aggregations\nspending = pd.read_sql_query(\"\"\"\n    SELECT category, SUM(amount) as total\n    FROM transactions\n    WHERE amount &lt; 0\n    GROUP BY category\n    ORDER BY total\n\"\"\", conn)\n\nconn.close()\n</code></pre>"},{"location":"database-schema/#common-queries","title":"Common Queries","text":"<p>Monthly Spending:</p> <pre><code>SELECT \n    strftime('%Y-%m', date) as month,\n    SUM(CASE WHEN amount &lt; 0 THEN amount ELSE 0 END) as spending,\n    SUM(CASE WHEN amount &gt; 0 THEN amount ELSE 0 END) as income\nFROM transactions\nGROUP BY month\nORDER BY month DESC;\n</code></pre> <p>Category Breakdown:</p> <pre><code>SELECT \n    category,\n    COUNT(*) as transaction_count,\n    SUM(amount) as total_amount,\n    AVG(amount) as avg_amount\nFROM transactions\nWHERE amount &lt; 0\nGROUP BY category\nORDER BY total_amount;\n</code></pre> <p>Recent Transactions:</p> <pre><code>SELECT date, description, amount, category\nFROM transactions\nORDER BY date DESC, created_at DESC\nLIMIT 20;\n</code></pre> <p>Largest Expenses:</p> <pre><code>SELECT date, description, amount, category\nFROM transactions\nWHERE amount &lt; 0\nORDER BY amount\nLIMIT 10;\n</code></pre>"},{"location":"database-schema/#database-maintenance","title":"Database Maintenance","text":""},{"location":"database-schema/#backup","title":"Backup","text":"<pre><code># Create backup\nsqlite3 data/finance.db \".backup data/finance_backup.db\"\n\n# Or simple copy\ncp data/finance.db data/finance_backup_$(date +%Y%m%d).db\n</code></pre>"},{"location":"database-schema/#vacuum-optimize","title":"Vacuum (Optimize)","text":"<pre><code>-- Reclaim unused space\nVACUUM;\n\n-- Analyze for query optimization\nANALYZE;\n</code></pre>"},{"location":"database-schema/#reset-database","title":"Reset Database","text":"<pre><code># \u26a0\ufe0f WARNING: This deletes all data!\n\n# Option 1: Delete file\nrm data/finance.db\n\n# Option 2: Drop tables\nsqlite3 data/finance.db \"DROP TABLE IF EXISTS transactions; DROP TABLE IF EXISTS mem_labels;\"\n</code></pre>"},{"location":"database-schema/#indexes-for-performance","title":"Indexes for Performance","text":"<p>As your database grows, add indexes:</p> <pre><code>-- Index on date for faster date range queries\nCREATE INDEX idx_transactions_date ON transactions(date);\n\n-- Index on category for faster filtering\nCREATE INDEX idx_transactions_category ON transactions(category);\n\n-- Composite index for common query patterns\nCREATE INDEX idx_transactions_date_category ON transactions(date, category);\n</code></pre> <p>When to Add Indexes:</p> <ul> <li>\u2705 When you have &gt;10,000 transactions</li> <li>\u2705 If queries feel slow</li> <li>\u2705 On frequently filtered columns</li> </ul> <p>Trade-off: - \u2705 Faster SELECT queries - \u274c Slightly slower INSERT (minimal impact)</p>"},{"location":"database-schema/#schema-migrations","title":"Schema Migrations","text":"<p>If you need to change the schema manually:</p>"},{"location":"database-schema/#add-column","title":"Add Column","text":"<pre><code>ALTER TABLE transactions ADD COLUMN account TEXT;\n</code></pre>"},{"location":"database-schema/#rename-table","title":"Rename Table","text":"<pre><code>ALTER TABLE transactions RENAME TO transactions_old;\nCREATE TABLE transactions (...);\nINSERT INTO transactions SELECT ... FROM transactions_old;\nDROP TABLE transactions_old;\n</code></pre>"},{"location":"database-schema/#change-column-type","title":"Change Column Type","text":"<p>SQLite doesn't support ALTER COLUMN, so use this pattern:</p> <pre><code>-- 1. Create new table with correct schema\nCREATE TABLE transactions_new (\n    id INTEGER PRIMARY KEY,\n    date TEXT,\n    amount REAL,  -- Changed from INTEGER to REAL\n    ...\n);\n\n-- 2. Copy data\nINSERT INTO transactions_new SELECT * FROM transactions;\n\n-- 3. Drop old table\nDROP TABLE transactions;\n\n-- 4. Rename new table\nALTER TABLE transactions_new RENAME TO transactions;\n</code></pre>"},{"location":"database-schema/#advanced-features","title":"Advanced Features","text":""},{"location":"database-schema/#json-columns","title":"JSON Columns","text":"<p>Store complex data as JSON:</p> <pre><code>-- Store metadata as JSON\nCREATE TABLE transactions (\n    ...\n    metadata TEXT  -- Stores JSON string\n);\n\n-- Insert with JSON\nINSERT INTO transactions (date, amount, metadata)\nVALUES ('2025-01-15', -45.67, '{\"store_id\": \"123\", \"cashier\": \"Alice\"}');\n\n-- Query JSON (SQLite 3.38+)\nSELECT json_extract(metadata, '$.store_id') FROM transactions;\n</code></pre>"},{"location":"database-schema/#triggers","title":"Triggers","text":"<p>Auto-update <code>updated_at</code> timestamp:</p> <pre><code>CREATE TRIGGER update_timestamp\nAFTER UPDATE ON transactions\nFOR EACH ROW\nBEGIN\n    UPDATE transactions SET updated_at = CURRENT_TIMESTAMP\n    WHERE id = NEW.id;\nEND;\n</code></pre>"},{"location":"database-schema/#views","title":"Views","text":"<p>Create virtual tables for common queries:</p> <pre><code>CREATE VIEW monthly_summary AS\nSELECT \n    strftime('%Y-%m', date) as month,\n    category,\n    SUM(amount) as total\nFROM transactions\nGROUP BY month, category;\n\n-- Query the view\nSELECT * FROM monthly_summary WHERE month = '2025-01';\n</code></pre>"},{"location":"database-schema/#database-limits","title":"Database Limits","text":"Limit Value Max database size 281 TB (practical: disk space) Max row size 1 GB Max column count 2000 columns per table Max table count Unlimited (practical: thousands) <p>For reference: 1 million transactions \u2248 100-200 MB</p>"},{"location":"database-schema/#troubleshooting","title":"Troubleshooting","text":""},{"location":"database-schema/#database-locked","title":"Database Locked","text":"<p>Error: <code>database is locked</code></p> <p>Cause: Multiple processes accessing simultaneously</p> <p>Solution: <pre><code># Increase timeout\nconn = sqlite3.connect('data/finance.db', timeout=20.0)\n</code></pre></p>"},{"location":"database-schema/#corrupt-database","title":"Corrupt Database","text":"<p>Check integrity: <pre><code>PRAGMA integrity_check;\n</code></pre></p> <p>If corrupted, restore from backup: <pre><code>cp data/finance_backup.db data/finance.db\n</code></pre></p>"},{"location":"database-schema/#slow-queries","title":"Slow Queries","text":"<p>Check query plan: <pre><code>EXPLAIN QUERY PLAN\nSELECT * FROM transactions WHERE date &gt; '2025-01-01';\n</code></pre></p> <p>Add indexes if needed (see Indexes section above)</p>"},{"location":"database-schema/#next-steps","title":"Next Steps","text":"<ul> <li>Agent Workflow - How data gets into the database</li> <li>LLM Integration - AI-powered data extraction</li> <li>API Reference - Python API for database operations</li> </ul> <p>Dynamic Schema</p> <p>Remember: The schema adapts to your data. You rarely need to manually create tables!</p>"},{"location":"faq/","title":"Frequently Asked Questions (FAQ)","text":"<p>Common questions about Finance AI Dashboard.</p>"},{"location":"faq/#general","title":"General","text":""},{"location":"faq/#what-is-finance-ai-dashboard","title":"What is Finance AI Dashboard?","text":"<p>Finance AI Dashboard is an offline personal finance manager that uses local AI to automatically parse, categorize, and visualize your financial transactions from bank statements, credit card statements, and other financial documents.</p> <p>Key Features: - \ud83e\udd16 AI-powered document understanding - \ud83d\udd12 100% offline and private - \ud83d\udcca Automatic categorization - \ud83d\udcc8 Interactive visualizations - \ud83d\udcbe Dynamic database schema</p>"},{"location":"faq/#is-my-financial-data-safe","title":"Is my financial data safe?","text":"<p>Yes - 100% safe and private!</p> <p>Your data never leaves your computer: - \u2705 All processing happens locally - \u2705 No internet connection required - \u2705 No cloud uploads - \u2705 No external API calls - \u2705 Open source code (you can audit it)</p> <pre><code>graph LR\n    A[Your Files] --&gt; B[Your Computer]\n    B --&gt; C[Local AI]\n    C --&gt; D[Local Database]\n\n    B -.-&gt;|Never| E[\u274c Internet]\n\n    style E fill:#ffcdd2</code></pre>"},{"location":"faq/#do-i-need-an-internet-connection","title":"Do I need an internet connection?","text":"<p>No! Finance AI works completely offline after initial setup.</p> <p>Internet only needed for: - Downloading the AI model (one-time, 4.7GB) - Installing dependencies (one-time)</p> <p>After setup: - \u2705 Process files offline - \u2705 View dashboard offline - \u2705 Everything works offline</p>"},{"location":"faq/#is-it-free","title":"Is it free?","text":"<p>Yes! Finance AI is completely free and open source.</p> <ul> <li>\u2705 No subscription fees</li> <li>\u2705 No hidden costs</li> <li>\u2705 No \"premium\" features</li> <li>\u2705 MIT License (use freely)</li> </ul>"},{"location":"faq/#what-makes-this-ai-first","title":"What makes this \"AI-first\"?","text":"<p>Unlike traditional finance apps that use keyword matching:</p> <p>Traditional Apps: <pre><code>IF description contains \"Whole Foods\" THEN category = \"Groceries\"\n</code></pre></p> <p>Finance AI: <pre><code>AI understands: \"WHOLEFDS #123\" \u2192 Whole Foods \u2192 Grocery store \u2192 Groceries\n</code></pre></p> <p>The AI understands context, not just keywords!</p>"},{"location":"faq/#installation-setup","title":"Installation &amp; Setup","text":""},{"location":"faq/#what-are-the-system-requirements","title":"What are the system requirements?","text":"<p>Minimum: - Python 3.10+ - 6GB RAM - 5GB free disk space - macOS, Linux, or Windows</p> <p>Recommended: - Python 3.11+ - 8GB+ RAM - SSD storage - 4+ CPU cores</p>"},{"location":"faq/#how-long-does-installation-take","title":"How long does installation take?","text":"<p>Time Breakdown:</p> Step Duration Download AI model 5-10 min (4.7GB) Install dependencies 2-5 min First app startup 5-10 sec Total ~15 minutes <p>Subsequent startups: 2-5 seconds</p>"},{"location":"faq/#can-i-use-a-different-ai-model","title":"Can I use a different AI model?","text":"<p>Yes! You can use any GGUF-format model.</p> <p>Popular alternatives:</p> Model Size Speed Quality TinyLlama-1.1B 600MB Fast Basic Mistral-7B (default) 4.7GB Medium Good Llama-2-13B 13GB Slow Best <p>How to switch:</p> <p>Edit <code>llm_handler.py</code>: <pre><code>model_path = Path(\"your-model-name.gguf\")\n</code></pre></p> <p>See: LLM Integration Guide</p>"},{"location":"faq/#do-i-need-a-gpu","title":"Do I need a GPU?","text":"<p>No! Finance AI works fine on CPU.</p> <p>Performance:</p> Hardware Processing Time CPU only 2-5 seconds M1/M2 Mac (Metal) 1-2 seconds NVIDIA GPU 1-2 seconds <p>GPU support (optional): - macOS: Metal (M1/M2) - Linux: CUDA (NVIDIA) - Windows: CUDA (NVIDIA)</p>"},{"location":"faq/#using-the-dashboard","title":"Using the Dashboard","text":""},{"location":"faq/#what-file-formats-are-supported","title":"What file formats are supported?","text":"<p>Fully Supported: - \u2705 CSV (.csv) - \u2705 PDF (.pdf) - \u2705 Text (.txt, .text)</p> <p>Coming Soon: - \ud83d\udd04 Excel (.xlsx, .xls) - \ud83d\udd04 OFX (.ofx) - \ud83d\udd04 QIF (.qif)</p>"},{"location":"faq/#can-i-upload-bank-statements-directly","title":"Can I upload bank statements directly?","text":"<p>Yes! The AI can read:</p> <ul> <li>Bank account statements (PDF or CSV)</li> <li>Credit card statements (PDF or CSV)</li> <li>Investment statements</li> <li>Invoices and receipts</li> <li>Any financial document</li> </ul> <p>Supported banks: All banks! The AI adapts to any format.</p>"},{"location":"faq/#how-accurate-is-the-categorization","title":"How accurate is the categorization?","text":"<p>Typical accuracy: - First upload: 70-80% accurate - After training: 90-95% accurate</p> <p>Improves over time: 1. You upload transactions 2. AI guesses categories (70-80% right) 3. You correct wrong ones 4. AI learns from corrections 5. Next upload is more accurate!</p>"},{"location":"faq/#can-i-edit-transactions","title":"Can I edit transactions?","text":"<p>Yes! Click any transaction to:</p> <ul> <li>\u270f\ufe0f Change category</li> <li>\u270f\ufe0f Edit description</li> <li>\u270f\ufe0f Update amount</li> <li>\u270f\ufe0f Change date</li> </ul> <p>The AI learns from your edits!</p>"},{"location":"faq/#how-do-i-add-custom-categories","title":"How do I add custom categories?","text":"<p>Option 1: Edit app.py</p> <pre><code>categories = [\n    'Groceries', 'Dining', 'Transport',\n    'Your Custom Category',  # Add here\n    'Another Category'\n]\n</code></pre> <p>Option 2: Let AI create them</p> <p>Upload a file with new categories in the data: <pre><code>Date,Description,Amount,Category\n2025-01-15,Dog Food,-45.67,Pet Care\n</code></pre></p> <p>The AI will recognize \"Pet Care\" and use it going forward!</p>"},{"location":"faq/#can-i-track-multiple-accounts","title":"Can I track multiple accounts?","text":"<p>Yes! Upload statements from different accounts:</p> <pre><code>\u2713 chase_checking.csv: 42 records\n\u2713 chase_savings.csv: 12 records\n\u2713 amex_credit.pdf: 38 records\n</code></pre> <p>All transactions combine in one dashboard.</p> <p>To separate accounts:</p> <p>Add an \"account\" column in your CSV: <pre><code>Date,Description,Amount,Account\n2025-01-15,Groceries,-45.67,Checking\n2025-01-16,Savings deposit,500.00,Savings\n</code></pre></p>"},{"location":"faq/#how-do-i-export-my-data","title":"How do I export my data?","text":"<p>Method 1: SQLite Database</p> <pre><code># Copy database file\ncp data/finance.db my_finance_backup.db\n</code></pre> <p>Method 2: Export to CSV</p> <pre><code>sqlite3 data/finance.db\n\n# Export all transactions\n.mode csv\n.output transactions_export.csv\nSELECT * FROM transactions;\n.quit\n</code></pre> <p>Method 3: Python Script</p> <pre><code>import sqlite3\nimport pandas as pd\n\nconn = sqlite3.connect('data/finance.db')\ndf = pd.read_sql_query(\"SELECT * FROM transactions\", conn)\ndf.to_csv('export.csv', index=False)\n</code></pre>"},{"location":"faq/#technical-questions","title":"Technical Questions","text":""},{"location":"faq/#how-does-the-ai-work","title":"How does the AI work?","text":"<p>Three-Agent System:</p> <pre><code>graph LR\n    A[Upload File] --&gt; B[Agent 1: Extract]\n    B --&gt; C[Agent 2: Organize]\n    C --&gt; D[Agent 3: Database]\n    D --&gt; E[Dashboard]\n\n    style B fill:#e1f5ff\n    style C fill:#e8f5e9\n    style D fill:#fff3e0</code></pre> <ol> <li>Agent 1 (Extractor): Reads file and extracts raw data</li> <li>Agent 2 (Organizer): Structures data into transactions</li> <li>Agent 3 (Database): Creates/updates database schema and stores records</li> </ol> <p>See: AI Architecture | Agent Workflow</p>"},{"location":"faq/#what-is-dynamic-schema-evolution","title":"What is dynamic schema evolution?","text":"<p>The database adapts to your data automatically.</p> <p>Traditional Database: <pre><code>\u274c Must define schema first\n\u274c ALTER TABLE manually for new fields\n\u274c Rigid structure\n</code></pre></p> <p>Finance AI: <pre><code>\u2705 Tables created on-demand\n\u2705 Columns added automatically\n\u2705 Flexible structure\n</code></pre></p> <p>Example:</p> <p>Upload a budget file \u2192 <code>budgets</code> table created automatically! <pre><code>{\"month\": \"2025-01\", \"category\": \"Groceries\", \"planned\": 500}\n</code></pre> \u2193 <pre><code>CREATE TABLE budgets (month TEXT, category TEXT, planned REAL);\n</code></pre></p> <p>See: Database Schema</p>"},{"location":"faq/#where-is-data-stored","title":"Where is data stored?","text":"<p>Location: <code>data/finance.db</code></p> <p>Format: SQLite database</p> <p>Tables: - <code>transactions</code> - Financial transactions - <code>mem_labels</code> - Learned categorization rules - Dynamic tables - Created based on uploaded data</p> <p>Size: ~100KB per 1,000 transactions</p>"},{"location":"faq/#can-i-use-this-for-business-expenses","title":"Can I use this for business expenses?","text":"<p>Yes! Finance AI works for:</p> <ul> <li>\u2705 Personal finances</li> <li>\u2705 Freelance expenses</li> <li>\u2705 Small business accounting</li> <li>\u2705 Project budgeting</li> </ul> <p>Multi-entity tracking:</p> <p>Add columns for business/project: <pre><code>Date,Description,Amount,Category,Business\n2025-01-15,Office supplies,-45.67,Supplies,Acme Corp\n2025-01-16,Client lunch,-85.00,Dining,Acme Corp\n</code></pre></p>"},{"location":"faq/#can-i-run-this-on-a-server","title":"Can I run this on a server?","text":"<p>Yes, but...</p> <p>Finance AI is designed for local use. However, you can:</p> <p>Option 1: Personal Server <pre><code># Run on your home server\npython -m finance_ai --host=0.0.0.0 --port=8050\n\n# Access from other devices on your network\nhttp://your-server-ip:8050\n</code></pre></p> <p>Option 2: Cloud Server (Not Recommended) - \u26a0\ufe0f Less private (data on cloud) - \u26a0\ufe0f Requires strong authentication - \u26a0\ufe0f Network latency</p>"},{"location":"faq/#is-there-a-mobile-app","title":"Is there a mobile app?","text":"<p>Not yet! But you can:</p> <p>Option 1: Mobile Browser <pre><code>Open http://your-computer-ip:8050 in mobile browser\n</code></pre></p> <p>Option 2: Export Data <pre><code>Export to CSV and use mobile spreadsheet app\n</code></pre></p> <p>Future Plans: - \ud83d\udcf1 Native mobile app - \ud83d\udd04 Mobile-optimized web interface</p>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"faq/#why-is-processing-slow","title":"Why is processing slow?","text":"<p>Common causes:</p> <ol> <li>First upload: Model loads (5-10 sec) - normal!</li> <li>Large file: &gt;10MB takes longer</li> <li>Low RAM: Close other apps</li> <li>CPU threads: Adjust in <code>llm_handler.py</code></li> </ol> <p>See: Troubleshooting: Slow Processing</p>"},{"location":"faq/#why-arent-my-transactions-showing","title":"Why aren't my transactions showing?","text":"<p>Check:</p> <ol> <li>\u2705 Date range filter (expand to \"All Time\")</li> <li>\u2705 Category filters (check all categories)</li> <li>\u2705 Database query: <code>sqlite3 data/finance.db \"SELECT COUNT(*) FROM transactions;\"</code></li> </ol> <p>See: Troubleshooting: Transactions Not Appearing</p>"},{"location":"faq/#the-categories-are-wrong","title":"The categories are wrong!","text":"<p>This is normal! The AI learns over time.</p> <p>Fix: 1. Click transaction 2. Change category 3. AI remembers for next time</p> <p>After 3-5 uploads: Accuracy improves to 90-95%!</p>"},{"location":"faq/#can-i-reset-everything","title":"Can I reset everything?","text":"<p>Yes! To start fresh:</p> <pre><code># \u26a0\ufe0f Backup first!\ncp data/finance.db data/backup.db\n\n# Delete database\nrm data/finance.db\n\n# Restart app (creates new database)\npython -m finance_ai\n</code></pre>"},{"location":"faq/#advanced-usage","title":"Advanced Usage","text":""},{"location":"faq/#can-i-automate-uploads","title":"Can I automate uploads?","text":"<p>Yes! Use Python scripting:</p> <pre><code>from finance_ai.agents import AgentWorkflow\n\nworkflow = AgentWorkflow()\n\n# Process multiple files\nfiles = ['jan.csv', 'feb.csv', 'mar.csv']\nfor file in files:\n    result = workflow.process_file(file, file)\n    print(f\"{file}: {result['records']} records\")\n</code></pre> <p>Scheduled uploads:</p> <pre><code># Cron job (Linux/Mac) - daily at 8am\n0 8 * * * cd /path/to/finance-ai &amp;&amp; .venv/bin/python batch_upload.py\n</code></pre>"},{"location":"faq/#can-i-query-data-with-python","title":"Can I query data with Python?","text":"<p>Yes! Use pandas:</p> <pre><code>import sqlite3\nimport pandas as pd\n\n# Connect to database\nconn = sqlite3.connect('data/finance.db')\n\n# Query transactions\ndf = pd.read_sql_query(\"\"\"\n    SELECT * FROM transactions \n    WHERE date &gt;= '2025-01-01'\n\"\"\", conn)\n\n# Analyze\nspending = df[df['amount'] &lt; 0].groupby('category')['amount'].sum()\nprint(spending)\n</code></pre>"},{"location":"faq/#can-i-customize-the-dashboard","title":"Can I customize the dashboard?","text":"<p>Yes! Edit <code>finance_ai/app.py</code> to:</p> <ul> <li>Change colors/theme</li> <li>Add new charts</li> <li>Modify layout</li> <li>Add custom filters</li> </ul> <p>Example: Add a new chart</p> <pre><code># In finance_ai/app.py, add to layout\ndcc.Graph(\n    id='my-custom-chart',\n    figure=px.line(df, x='date', y='balance')\n)\n</code></pre>"},{"location":"faq/#can-i-integrate-with-other-tools","title":"Can I integrate with other tools?","text":"<p>Yes! Export data to:</p> <p>CSV/Excel: <pre><code>df.to_csv('export.csv')\ndf.to_excel('export.xlsx')\n</code></pre></p> <p>JSON API: <pre><code># Create a REST API endpoint\n@app.route('/api/transactions')\ndef get_transactions():\n    conn = sqlite3.connect('data/finance.db')\n    df = pd.read_sql_query(\"SELECT * FROM transactions\", conn)\n    return df.to_json()\n</code></pre></p> <p>Power BI / Tableau:</p> <p>Import <code>data/finance.db</code> directly (SQLite connector)</p>"},{"location":"faq/#contributing","title":"Contributing","text":""},{"location":"faq/#how-can-i-contribute","title":"How can I contribute?","text":"<p>We welcome contributions!</p> <p>Ways to help: - \ud83d\udc1b Report bugs - \ud83d\udca1 Suggest features - \ud83d\udcd6 Improve documentation - \ud83e\uddd1\u200d\ud83d\udcbb Submit code (PRs welcome!) - \u2b50 Star the repo</p> <p>See: Contributing Guide</p>"},{"location":"faq/#can-i-add-my-own-agents","title":"Can I add my own agents?","text":"<p>Yes! The agent system is extensible.</p> <p>Example: Create a Budget Agent</p> <pre><code># In agents.py\nclass BudgetAgent:\n    def __init__(self, llm_handler):\n        self.llm = llm_handler\n\n    def analyze_spending(self, month):\n        # Use LLM to analyze spending patterns\n        pass\n\n# Add to workflow\nworkflow.budget_agent = BudgetAgent(llm)\n</code></pre>"},{"location":"faq/#where-can-i-get-help","title":"Where can I get help?","text":"<ul> <li>\ud83d\udcd6 Read the Documentation</li> <li>\ud83d\udc1b Check Troubleshooting Guide</li> <li>\ud83d\udcac Ask in GitHub Discussions</li> <li>\ud83d\udc1b Open an issue on GitHub</li> </ul>"},{"location":"faq/#future-features","title":"Future Features","text":""},{"location":"faq/#whats-coming-next","title":"What's coming next?","text":"<p>Roadmap:</p> <p>v2.0 (Q1 2025): - \ud83d\udcf1 Mobile-responsive UI - \ud83d\udcb0 Budget tracking - \ud83d\udcca Advanced reports - \ud83d\udd04 Recurring transaction detection</p> <p>v3.0 (Q2 2025): - \ud83e\udd16 AI-powered insights and recommendations - \ud83d\udcc8 Investment tracking - \ud83c\udf0d Multi-currency support - \ud83d\udd17 Bank sync (optional)</p> <p>See: Full Roadmap</p>"},{"location":"faq/#can-i-request-features","title":"Can I request features?","text":"<p>Yes! Open a GitHub issue:</p> <ol> <li>Go to GitHub repository</li> <li>Click \"Issues\" \u2192 \"New Issue\"</li> <li>Describe your feature request</li> <li>We'll review and discuss!</li> </ol>"},{"location":"faq/#comparison","title":"Comparison","text":""},{"location":"faq/#how-is-this-different-from-mintynabpersonal-capital","title":"How is this different from Mint/YNAB/Personal Capital?","text":"Feature Finance AI Mint/YNAB Personal Capital Privacy 100% offline Cloud-based Cloud-based Cost Free $15/mo Free (ads) AI-Powered \u2705 Yes \u274c No \u274c No Custom Categories \u2705 Unlimited \u274c Limited \u274c Limited File Formats Any CSV only API only Bank Sync Manual Automatic Automatic Self-Hosted \u2705 Yes \u274c No \u274c No <p>Finance AI is for you if: - \ud83d\udd12 Privacy is important - \ud83e\udd16 Want AI understanding - \ud83d\udcb0 Don't want subscriptions - \ud83d\udee0\ufe0f Like control &amp; customization</p> <p>Other tools are better if: - \ud83d\udd04 Need automatic bank sync - \ud83d\udcf1 Require mobile app - \ud83d\udcbc Want managed service</p> <p>Still have questions?</p> <ul> <li>Check the Troubleshooting Guide</li> <li>Read the Documentation</li> <li>Ask in GitHub Discussions</li> <li>Open an issue</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide will help you install and run Finance AI Dashboard on your system.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>Python 3.10 or higher installed</li> <li>8GB RAM minimum (16GB recommended for better performance)</li> <li>~5GB free disk space for the AI model and dependencies</li> <li>Terminal/Command Line access</li> </ul> <p>Supported Platforms</p> <p>Finance AI works on macOS, Linux, and Windows. Installation steps may vary slightly.</p>"},{"location":"getting-started/#installation-methods","title":"Installation Methods","text":"Automated (Recommended)ManualFrom Requirements (exported) <p>The easiest way to install Finance AI is using the automated setup script:</p> <pre><code># 1. Clone the repository\ngit clone https://github.com/PhilipNJ/finance-ai.git\ncd finance-ai\n\n# 2. Run setup script\n./setup.sh\n</code></pre> <p>The script will: - \u2705 Create a virtual environment - \u2705 Install all Python dependencies - \u2705 Install llama-cpp-python with correct flags for your system - \u2705 Check for the AI model file - \u2705 Verify Tesseract OCR (optional)</p> <p>If you prefer using <code>requirements.txt</code>, export it from Poetry first:</p> <pre><code># 1. Clone and navigate\ngit clone https://github.com/PhilipNJ/finance-ai.git\ncd finance-ai\n\n# 2. Create virtual environment\npython3 -m venv .venv\nsource .venv/bin/activate\n\n# 3. Export and install requirements\nmake export-reqs\npip install -r requirements.txt\n\n# 4. Install llama-cpp-python separately with system-specific flags\n# (See Manual tab for your system)\n\n# 5. Download AI model (see Manual tab)\n</code></pre>"},{"location":"getting-started/#step-1-create-virtual-environment","title":"Step 1: Create Virtual Environment","text":"<pre><code>python3 -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n</code></pre>"},{"location":"getting-started/#step-2-install-base-dependencies","title":"Step 2: Install Base Dependencies","text":"<pre><code>pip install --upgrade pip\npip install dash pandas plotly pdfplumber pytesseract Pillow\n</code></pre>"},{"location":"getting-started/#step-3-install-llm-support","title":"Step 3: Install LLM Support","text":"<p>macOS (Apple Silicon): <pre><code>CMAKE_ARGS=\"-DLLAMA_METAL=on\" pip install llama-cpp-python==0.2.90\n</code></pre></p> <p>macOS (Intel): <pre><code>pip install llama-cpp-python==0.2.90\n</code></pre></p> <p>Linux (with CUDA): <pre><code>CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python==0.2.90\n</code></pre></p> <p>Linux (CPU only): <pre><code>pip install llama-cpp-python==0.2.90\n</code></pre></p> <p>Windows: <pre><code>pip install llama-cpp-python==0.2.90\n</code></pre></p>"},{"location":"getting-started/#step-4-download-ai-model","title":"Step 4: Download AI Model","text":"<p>Download the Mistral-7B model (~4.7GB):</p> <pre><code># Using wget\nwget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q5_0.gguf\n\n# Or using curl\ncurl -L -o mistral-7b-instruct-v0.1.Q5_0.gguf \\\n  https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q5_0.gguf\n</code></pre>"},{"location":"getting-started/#verification","title":"Verification","text":""},{"location":"getting-started/#pre-flight-check","title":"Pre-Flight Check","text":"<p>Run the pre-flight check to verify everything is installed correctly:</p> <pre><code>poetry run python scripts/preflight_check.py\n</code></pre> <p>Expected output:</p> <pre><code>======================================================================\n\ud83e\udd16 Finance AI Dashboard - Pre-Flight Check\n======================================================================\nChecking AI Dependencies...\n----------------------------------------------------------------------\n\u2705 llama-cpp-python installed\n\u2705 AI model found: mistral-7b-instruct-v0.1.Q5_0.gguf (4766.2 MB)\n\nChecking Other Dependencies...\n----------------------------------------------------------------------\n\u2705 dash (Dash framework)\n\u2705 pandas (Data processing)\n\u2705 plotly (Visualization)\n\u2705 pdfplumber (PDF parsing)\n\nChecking Directories...\n----------------------------------------------------------------------\n\u2705 Directory exists: data\n\u2705 Directory exists: data/uploads\n\u2705 Directory exists: data/temp\n\n======================================================================\n\u2705 ALL CHECKS PASSED - Ready to launch!\n======================================================================\n</code></pre>"},{"location":"getting-started/#installation-test","title":"Installation Test","text":"<p>Run the full installation test suite:</p> <pre><code>python3 test_installation.py\n</code></pre> <p>This will test: - \u2705 All imports work correctly - \u2705 AI model file is present and valid - \u2705 Agent modules load successfully - \u2705 Database connection works - \u2705 Sample extraction functions</p>"},{"location":"getting-started/#running-the-application","title":"Running the Application","text":""},{"location":"getting-started/#start-the-app","title":"Start the App","text":"<pre><code>python3 app.py\n</code></pre> <p>Expected startup output:</p> <pre><code>======================================================================\n\ud83e\udd16 Finance AI Dashboard - Starting Up\n======================================================================\n\u2705 LLM dependencies available\n\ud83d\udd27 Initializing AI agent workflow...\n\ud83e\udd16 Initializing AI engine with mistral-7b-instruct-v0.1.Q5_0.gguf...\nLoading LLM from mistral-7b-instruct-v0.1.Q5_0.gguf...\nLLM loaded successfully.\n\u2705 AI agents ready!\n======================================================================\n\u2705 Finance AI Dashboard ready!\n======================================================================\n\nDash is running on http://127.0.0.1:8050/\n</code></pre>"},{"location":"getting-started/#access-the-dashboard","title":"Access the Dashboard","text":"<p>Open your browser and navigate to:</p> <pre><code>http://127.0.0.1:8050\n</code></pre> <p>You should see the Finance AI Dashboard home screen with the upload interface.</p>"},{"location":"getting-started/#optional-tesseract-ocr","title":"Optional: Tesseract OCR","text":"<p>For OCR support (reading scanned PDFs and images):</p> macOSUbuntu/DebianWindows <pre><code>brew install tesseract\n</code></pre> <pre><code>sudo apt-get update\nsudo apt-get install tesseract-ocr\n</code></pre> <p>Download and install from: https://github.com/UB-Mannheim/tesseract/wiki</p>"},{"location":"getting-started/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/#common-issues","title":"Common Issues","text":"<p>llama-cpp-python installation fails</p> <p>Problem: Build errors when installing llama-cpp-python</p> <p>Solutions:</p> <ol> <li> <p>Install build tools:     <pre><code># macOS\nxcode-select --install\n\n# Ubuntu/Debian\nsudo apt-get install build-essential\n</code></pre></p> </li> <li> <p>Use pre-built wheels:     <pre><code>pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu\n</code></pre></p> </li> </ol> <p>Model file not found</p> <p>Problem: <code>Model file not found at mistral-7b-instruct-v0.1.Q5_0.gguf</code></p> <p>Solution: Download the model file (see Installation Step 4 above)</p> <p>Out of memory</p> <p>Problem: System runs out of RAM when loading model</p> <p>Solutions:</p> <ol> <li> <p>Use a smaller model (Q4 quantization):     <pre><code>wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_0.gguf\n</code></pre></p> </li> <li> <p>Adjust context window in <code>llm_handler.py</code>:     <pre><code>LLMHandler(n_ctx=2048)  # Reduce from default 4096\n</code></pre></p> </li> </ol> <p>Import errors</p> <p>Problem: <code>ModuleNotFoundError</code> when running the app</p> <p>Solution: Activate virtual environment first: <pre><code>source .venv/bin/activate  # macOS/Linux\n.venv\\Scripts\\activate      # Windows\n</code></pre></p> <p>For more issues, see the Troubleshooting Guide.</p>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<p>Now that you have Finance AI installed and running:</p> <ol> <li>Quick Start Guide - Upload your first document</li> <li>Dashboard Guide - Explore the interface</li> <li>AI Architecture - Understand how it works</li> </ol> <p>Performance Tip</p> <p>On first run, the AI model takes 5-10 seconds to load. Subsequent uploads are much faster (2-5 seconds) as the model stays in memory.</p>"},{"location":"quick-start/","title":"Quick Start Tutorial","text":"<p>Get up and running with Finance AI Dashboard in 5 minutes.</p>"},{"location":"quick-start/#prerequisites","title":"Prerequisites","text":"<ul> <li>\u2705 Python 3.10 or newer</li> <li>\u2705 6GB free RAM (for the AI model)</li> <li>\u2705 5GB free disk space</li> <li>\u2705 Basic terminal/command line knowledge</li> </ul>"},{"location":"quick-start/#installation","title":"Installation","text":""},{"location":"quick-start/#option-1-automated-recommended","title":"Option 1: Automated (Recommended)","text":"macOS / LinuxWindows <pre><code># Clone or download the project\ncd finance-ai\n\n# Run the installation script\npoetry run python scripts/preflight_check.py\n\n# If successful, the app will start automatically!\n</code></pre> <pre><code># Clone or download the project\ncd finance-ai\n\n# Run the installation script\npoetry run python scripts/preflight_check.py\n\n# If successful, the app will start automatically!\n</code></pre>"},{"location":"quick-start/#option-2-manual","title":"Option 2: Manual","text":"<pre><code># 1. Create virtual environment\npython3 -m venv .venv\n\n# 2. Activate it\nsource .venv/bin/activate  # macOS/Linux\n# OR\n.venv\\Scripts\\activate  # Windows\n\n# 3. Install dependencies\npip install --upgrade pip\n# If using pip, first export requirements from Poetry in project root:\n#   make export-reqs\npip install -r requirements.txt\n\n# 4. Start the app\npython -m finance_ai\n</code></pre>"},{"location":"quick-start/#first-launch","title":"First Launch","text":"<p>When you run the app for the first time:</p> <pre><code>python -m finance_ai\n</code></pre> <p>You'll see:</p> <pre><code>\ud83e\udd16 Finance AI Dashboard - Starting...\n\ud83d\udce6 Checking LLM model...\n\u2713 Model found: mistral-7b-instruct-v0.1.Q5_0.gguf (4.7 GB)\n\ud83e\udde0 Loading AI model... (this may take 5-10 seconds)\n\u2713 LLM loaded successfully!\n\ud83c\udf10 Dashboard running at: http://127.0.0.1:8050\n\nPress Ctrl+C to stop.\n</code></pre> <p>First Load</p> <p>The first time takes 5-10 seconds to load the AI model. Subsequent starts are faster (~2 seconds).</p>"},{"location":"quick-start/#your-first-upload","title":"Your First Upload","text":""},{"location":"quick-start/#1-open-the-dashboard","title":"1. Open the Dashboard","text":"<p>Navigate to http://127.0.0.1:8050 in your browser:</p> <p></p>"},{"location":"quick-start/#2-prepare-a-file","title":"2. Prepare a File","text":"<p>You can upload:</p> <ul> <li>CSV files - Bank exports, credit card statements</li> <li>PDF files - Bank statements, invoices, receipts</li> <li>Text files - Any financial document</li> </ul> <p>Example CSV</p> <p>Create a test file called <code>test_transactions.csv</code>:</p> <pre><code>Date,Description,Amount\n2025-01-15,Whole Foods Market,45.67\n2025-01-16,Coffee Shop,5.25\n2025-01-20,Gas Station,52.00\n2025-01-22,Amazon Purchase,28.99\n2025-01-25,Salary,3500.00\n</code></pre>"},{"location":"quick-start/#3-upload-the-file","title":"3. Upload the File","text":"<ol> <li>Click the Upload Area or drag &amp; drop your file</li> <li>Wait for the AI to process (2-5 seconds)</li> <li>See the success message: \u2713 test_transactions.csv: 5 records processed \ud83e\udd16</li> </ol>"},{"location":"quick-start/#4-view-your-data","title":"4. View Your Data","text":"<p>Scroll down to see:</p> <ul> <li>Date Range Selector - Filter by time period</li> <li>Category Filter - Show/hide categories</li> <li>Transaction Table - All your transactions</li> <li>Spending Chart - Visual breakdown by category</li> </ul> <p></p>"},{"location":"quick-start/#understanding-the-ai-processing","title":"Understanding the AI Processing","text":"<p>Here's what happens when you upload:</p> <pre><code>sequenceDiagram\n    participant You\n    participant Dashboard\n    participant AI\n    participant Database\n\n    You-&gt;&gt;Dashboard: Upload file\n    Dashboard-&gt;&gt;AI: Process file\n    Note over AI: Agent 1: Extract data\n    Note over AI: Agent 2: Organize by type\n    Note over AI: Agent 3: Write to database\n    AI-&gt;&gt;Database: Store transactions\n    Database-&gt;&gt;Dashboard: Success\n    Dashboard-&gt;&gt;You: \u2713 Records processed \ud83e\udd16</code></pre>"},{"location":"quick-start/#what-the-ai-does","title":"What the AI Does:","text":"<ol> <li>Reads your file (CSV, PDF, or text)</li> <li>Understands the structure and content</li> <li>Extracts financial data (dates, amounts, descriptions)</li> <li>Categorizes transactions automatically</li> <li>Stores everything in the database</li> </ol> <p>AI-Powered</p> <p>The AI can understand almost any format - even handwritten receipts (with OCR)!</p>"},{"location":"quick-start/#exploring-your-data","title":"Exploring Your Data","text":""},{"location":"quick-start/#filter-by-date","title":"Filter by Date","text":"<p>Use the date range selector to focus on specific time periods:</p> <pre><code>[Jan 1, 2025] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 [Jan 31, 2025]\n</code></pre>"},{"location":"quick-start/#filter-by-category","title":"Filter by Category","text":"<p>Toggle categories on/off to see specific spending areas:</p> <ul> <li>\u2705 Groceries</li> <li>\u2705 Dining</li> <li>\u2705 Transport</li> <li>\u274c Entertainment (hidden)</li> </ul>"},{"location":"quick-start/#edit-transactions","title":"Edit Transactions","text":"<p>Click on any transaction to:</p> <ul> <li>Change the category</li> <li>Edit the description</li> <li>Update the amount</li> </ul> <p>The AI learns from your edits to improve future categorization!</p>"},{"location":"quick-start/#common-file-formats","title":"Common File Formats","text":""},{"location":"quick-start/#bank-statements-csv","title":"Bank Statements (CSV)","text":"<p>Most banks let you export transactions as CSV:</p> <p>Chase Bank: <pre><code>Details,Posting Date,Description,Amount,Type,Balance,Check or Slip #\nDEBIT,01/15/2025,\"WHOLE FOODS MARKET #123\",-45.67,Sale,2500.33,\n</code></pre></p> <p>Bank of America: <pre><code>Date,Description,Amount\n01/15/2025,WHOLEFDS #123,-45.67\n</code></pre></p> <p>Finance AI understands both formats automatically! \ud83c\udf89</p>"},{"location":"quick-start/#credit-card-statements-pdf","title":"Credit Card Statements (PDF)","text":"<p>Upload PDF statements directly - the AI will extract transactions:</p> <pre><code>CHASE CREDIT CARD STATEMENT\nStatement Period: 01/01/2025 - 01/31/2025\n\nDate       Description              Amount\n01/15      WHOLE FOODS MARKET       $45.67\n01/16      STARBUCKS #12345          $5.25\n</code></pre>"},{"location":"quick-start/#text-input","title":"Text Input","text":"<p>Even paste raw text:</p> <pre><code>Spent $45.67 at Whole Foods on January 15th\nCoffee was $5.25 at Starbucks yesterday\nGot gas for $52.00 last week\n</code></pre> <p>The AI will figure it out! \ud83e\udde0</p>"},{"location":"quick-start/#tips-tricks","title":"Tips &amp; Tricks","text":""},{"location":"quick-start/#1-upload-multiple-files","title":"1. Upload Multiple Files","text":"<p>Upload all your statements at once:</p> <pre><code>\u2713 chase_jan.csv: 42 records processed\n\u2713 amex_jan.pdf: 38 records processed  \n\u2713 cash_receipts.txt: 12 records processed\n</code></pre> <p>Total: 92 transactions in ~10 seconds!</p>"},{"location":"quick-start/#2-train-the-ai","title":"2. Train the AI","text":"<p>Edit categories when they're wrong:</p> <ol> <li>Click transaction \u2192 Change category to \"Groceries\"</li> <li>AI remembers: \"Whole Foods\" = Groceries</li> <li>Future uploads automatically categorize correctly</li> </ol>"},{"location":"quick-start/#3-mixed-formats","title":"3. Mixed Formats","text":"<p>Don't worry about format consistency - upload any mix:</p> <ul> <li>\u2705 CSV + PDF + Text</li> <li>\u2705 Different banks</li> <li>\u2705 Different layouts</li> </ul> <p>The AI adapts! \ud83c\udfaf</p>"},{"location":"quick-start/#troubleshooting","title":"Troubleshooting","text":""},{"location":"quick-start/#llm-model-not-found","title":"\u274c \"LLM model not found\"","text":"<p>Solution: Download the model:</p> <pre><code>wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q5_0.gguf\n</code></pre> <p>Place in project root directory.</p>"},{"location":"quick-start/#module-llama_cpp-not-found","title":"\u274c \"Module 'llama_cpp' not found\"","text":"<p>Solution: Install llama-cpp-python:</p> macOS (Metal GPU)LinuxWindows <pre><code>CMAKE_ARGS=\"-DLLAMA_METAL=on\" pip install llama-cpp-python\n</code></pre> <pre><code>pip install llama-cpp-python\n</code></pre> <pre><code>pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu\n</code></pre>"},{"location":"quick-start/#processing-failed","title":"\u274c \"Processing failed\"","text":"<p>Check:</p> <ol> <li>File is not corrupted</li> <li>File contains financial data</li> <li>LLM is loaded (check startup logs)</li> </ol> <p>Still stuck? See Troubleshooting Guide</p>"},{"location":"quick-start/#next-steps","title":"Next Steps","text":"<p>Now that you're up and running:</p> <ul> <li>\ud83d\udcd8 User Guide - Learn all features</li> <li>\ud83c\udfd7\ufe0f AI Architecture - How the AI works</li> <li>\ud83d\udee0\ufe0f Database Schema - Data structure</li> <li>\ud83e\udd16 LLM Integration - Customize the AI</li> </ul>"},{"location":"quick-start/#video-walkthrough","title":"Video Walkthrough","text":"<p>Coming Soon</p> <p>We're creating video tutorials. For now, follow this guide!</p> <p>You're All Set!</p> <p>You've successfully set up Finance AI Dashboard and processed your first transactions. Happy analyzing! \ud83d\udcca</p> <p>Need Help?</p> <ul> <li>Check the FAQ</li> <li>Read the Troubleshooting Guide</li> <li>Open an issue on GitHub</li> </ul>"},{"location":"troubleshooting/","title":"Troubleshooting Guide","text":"<p>Common issues and their solutions when using Finance AI Dashboard.</p>"},{"location":"troubleshooting/#installation-issues","title":"Installation Issues","text":""},{"location":"troubleshooting/#llm-model-not-found","title":"\u274c \"LLM model not found\"","text":"<p>Error Message: <pre><code>FileNotFoundError: LLM model not found at: mistral-7b-instruct-v0.1.Q5_0.gguf\n</code></pre></p> <p>Cause: The AI model file is missing from the project directory.</p> <p>Solution:</p> Option 1: Download from Hugging FaceOption 2: Manual DownloadOption 3: Use Different Model <pre><code>wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q5_0.gguf\n</code></pre> <ol> <li>Visit: https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF</li> <li>Download <code>mistral-7b-instruct-v0.1.Q5_0.gguf</code> (4.7 GB)</li> <li>Place in project root directory</li> </ol> <p>Edit <code>llm_handler.py</code>: <pre><code>model_path = Path(\"your-model-name.gguf\")\n</code></pre></p>"},{"location":"troubleshooting/#module-llama_cpp-not-found","title":"\u274c \"Module 'llama_cpp' not found\"","text":"<p>Error Message: <pre><code>ModuleNotFoundError: No module named 'llama_cpp'\n</code></pre></p> <p>Cause: <code>llama-cpp-python</code> package not installed or installation failed.</p> <p>Solution:</p> macOS (Metal GPU)Linux (CPU)Linux (CUDA GPU)Windows (CPU) <pre><code># Activate virtual environment first\nsource .venv/bin/activate\n\n# Install with Metal support\nCMAKE_ARGS=\"-DLLAMA_METAL=on\" pip install llama-cpp-python\n</code></pre> <pre><code>source .venv/bin/activate\npip install llama-cpp-python\n</code></pre> <pre><code>source .venv/bin/activate\nCMAKE_ARGS=\"-DLLAMA_CUDA=on\" pip install llama-cpp-python\n</code></pre> <pre><code>.venv\\Scripts\\activate\npip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu\n</code></pre> <p>If still failing: <pre><code># Install build dependencies\npip install --upgrade pip setuptools wheel cmake\n\n# Try again\npip install llama-cpp-python\n</code></pre></p>"},{"location":"troubleshooting/#cmake-not-found","title":"\u274c \"CMake not found\"","text":"<p>Error during llama-cpp-python installation: <pre><code>CMake must be installed to build llama-cpp-python\n</code></pre></p> <p>Solution:</p> macOSLinux (Ubuntu/Debian)Linux (Fedora/RHEL)Windows <pre><code>brew install cmake\n</code></pre> <pre><code>sudo apt-get update\nsudo apt-get install cmake build-essential\n</code></pre> <pre><code>sudo dnf install cmake gcc-c++\n</code></pre> <p>Download from: https://cmake.org/download/</p>"},{"location":"troubleshooting/#virtual-environment-issues","title":"\u274c Virtual Environment Issues","text":"<p>Error: <pre><code>command not found: python3\n# or\nThe virtual environment was not created successfully\n</code></pre></p> <p>Solution:</p> macOSLinuxWindows <pre><code># Install Python 3 via Homebrew\nbrew install python@3.11\n\n# Create virtual environment\npython3 -m venv .venv\n</code></pre> <pre><code># Install Python 3 and venv\nsudo apt-get install python3 python3-venv python3-dev\n\n# Create virtual environment\npython3 -m venv .venv\n</code></pre> <pre><code># Download Python from python.org\n# Then create virtual environment\npython -m venv .venv\n</code></pre>"},{"location":"troubleshooting/#runtime-issues","title":"Runtime Issues","text":""},{"location":"troubleshooting/#port-8050-already-in-use","title":"\u274c \"Port 8050 already in use\"","text":"<p>Error: <pre><code>OSError: [Errno 48] Address already in use\n</code></pre></p> <p>Cause: Another process is using port 8050.</p> <p>Solution:</p> Option 1: Kill existing processOption 2: Use different port <pre><code># Find process using port 8050\nlsof -ti:8050 | xargs kill -9\n\n# Then restart\npython -m finance_ai\n</code></pre> <p>Edit <code>finance_ai/app.py</code>: <pre><code>if __name__ == '__main__':\n    app.run_server(debug=True, port=8051)  # Changed from 8050\n</code></pre></p>"},{"location":"troubleshooting/#processing-failed-on-upload","title":"\u274c \"Processing failed\" on Upload","text":"<p>Error Message in UI: <pre><code>\u274c filename.pdf: Processing failed - [error details]\n</code></pre></p> <p>Possible Causes &amp; Solutions:</p>"},{"location":"troubleshooting/#1-llm-not-loaded","title":"1. LLM Not Loaded","text":"<p>Check startup logs: <pre><code>python -m finance_ai\n# Look for server startup messages\n</code></pre></p> <p>If not loaded, see LLM model not found</p>"},{"location":"troubleshooting/#2-corrupted-file","title":"2. Corrupted File","text":"<p>Try: - Re-download the file from your bank - Open file to verify it's not corrupted - Try converting to CSV</p>"},{"location":"troubleshooting/#3-empty-or-invalid-file","title":"3. Empty or Invalid File","text":"<p>Check: - File has actual content - File contains financial data - File is not password-protected (for PDFs)</p>"},{"location":"troubleshooting/#4-memory-issues","title":"4. Memory Issues","text":"<p>If processing large files: <pre><code># Check available memory\nfree -h  # Linux\nvm_stat  # macOS\n\n# If low, close other applications\n</code></pre></p>"},{"location":"troubleshooting/#slow-processing","title":"\u274c Slow Processing","text":"<p>Symptoms: - First upload takes &gt;30 seconds - Subsequent uploads take &gt;10 seconds</p> <p>Solutions:</p>"},{"location":"troubleshooting/#1-model-loading-slow-first-time","title":"1. Model Loading Slow (First Time)","text":"<p>Expected: - First upload: 7-15 seconds (model loads once) - Subsequent: 2-5 seconds</p> <p>If slower: <pre><code># Check model size\nls -lh mistral-7b-instruct-v0.1.Q5_0.gguf\n# Should be ~4.7GB\n\n# If much larger, consider quantized version\n</code></pre></p>"},{"location":"troubleshooting/#2-large-files","title":"2. Large Files","text":"<p>For files &gt;10MB: - Split into monthly chunks - Export smaller date ranges from bank</p>"},{"location":"troubleshooting/#3-cpu-usage","title":"3. CPU Usage","text":"<p>Optimize threads in <code>llm_handler.py</code>: <pre><code>self.llm = Llama(\n    model_path=str(self.model_path),\n    n_ctx=4096,\n    n_threads=4,  # Adjust based on your CPU\n    verbose=False\n)\n</code></pre></p> <p>CPU count guide: - 4 cores or less: <code>n_threads=2</code> - 6-8 cores: <code>n_threads=4</code> - 10+ cores: <code>n_threads=6</code></p>"},{"location":"troubleshooting/#database-locked","title":"\u274c Database Locked","text":"<p>Error: <pre><code>sqlite3.OperationalError: database is locked\n</code></pre></p> <p>Cause: Multiple processes accessing database simultaneously.</p> <p>Solution:</p> <pre><code># In finance_db.py, increase timeout\nconn = sqlite3.connect('data/finance.db', timeout=20.0)\n</code></pre> <p>Or: <pre><code># Close other instances of the app\npkill -f \"python -m finance_ai\"\n\n# Restart\npython -m finance_ai\n</code></pre></p>"},{"location":"troubleshooting/#memory-error","title":"\u274c Memory Error","text":"<p>Error: <pre><code>MemoryError: Not enough memory to load model\n</code></pre></p> <p>Requirements: - Minimum 6GB RAM - 4GB available for model - 2GB for processing</p> <p>Solutions:</p> Option 1: Close applicationsOption 2: Use smaller modelOption 3: Add swap space (Linux) <p>Free up RAM by closing: - Web browsers (especially Chrome) - Other Python processes - Large applications (IDEs, etc.)</p> <p>Replace with TinyLlama (only 600MB): <pre><code># In llm_handler.py\nmodel_path = Path(\"tinyllama-1.1b-chat-v1.0.Q5_K_M.gguf\")\n</code></pre></p> <p>Download from: https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF</p> <pre><code># Create 4GB swap file\nsudo fallocate -l 4G /swapfile\nsudo chmod 600 /swapfile\nsudo mkswap /swapfile\nsudo swapon /swapfile\n</code></pre>"},{"location":"troubleshooting/#data-issues","title":"Data Issues","text":""},{"location":"troubleshooting/#transactions-not-appearing","title":"\u274c Transactions Not Appearing","text":"<p>Symptoms: - Upload succeeds but dashboard shows no data - Transaction count shows 0</p> <p>Solutions:</p>"},{"location":"troubleshooting/#1-check-date-filter","title":"1. Check Date Filter","text":"<p>The date range filter might be excluding your data: - Expand date range to \"All Time\" - Check actual transaction dates in the file</p>"},{"location":"troubleshooting/#2-query-database-directly","title":"2. Query Database Directly","text":"<pre><code>sqlite3 data/finance.db\n\n# Check if transactions exist\nSELECT COUNT(*) FROM transactions;\n\n# View recent transactions\nSELECT * FROM transactions ORDER BY created_at DESC LIMIT 5;\n</code></pre>"},{"location":"troubleshooting/#3-check-category-filter","title":"3. Check Category Filter","text":"<p>Ensure categories are enabled: - Check all category checkboxes in the dashboard - Some categories might be unchecked</p>"},{"location":"troubleshooting/#wrong-categorization","title":"\u274c Wrong Categorization","text":"<p>Symptoms: - \"Whole Foods\" categorized as \"Dining\" instead of \"Groceries\" - Categories don't make sense</p> <p>Solutions:</p>"},{"location":"troubleshooting/#1-manually-fix-train","title":"1. Manually Fix &amp; Train","text":"<p>In the dashboard: 1. Click on the transaction 2. Change category to correct one 3. System learns for future uploads</p>"},{"location":"troubleshooting/#2-check-learned-mappings","title":"2. Check Learned Mappings","text":"<pre><code>sqlite3 data/finance.db\nSELECT * FROM mem_labels;\n</code></pre> <p>Remove incorrect mappings: <pre><code>DELETE FROM mem_labels WHERE keyword = 'whole foods';\n</code></pre></p>"},{"location":"troubleshooting/#3-improve-descriptions","title":"3. Improve Descriptions","text":"<p>More context = better categorization:</p> <p>Better: <pre><code>Whole Foods Market #123 - Seattle\n</code></pre></p> <p>vs: <pre><code>Purchase\n</code></pre></p>"},{"location":"troubleshooting/#duplicate-transactions","title":"\u274c Duplicate Transactions","text":"<p>Symptoms: - Same transaction appears multiple times - Upload shows doubled record count</p> <p>Cause: Uploading the same file multiple times.</p> <p>Solutions:</p>"},{"location":"troubleshooting/#1-manual-deduplication","title":"1. Manual Deduplication","text":"<pre><code>-- Find duplicates\nSELECT date, description, amount, COUNT(*) \nFROM transactions \nGROUP BY date, description, amount \nHAVING COUNT(*) &gt; 1;\n\n-- Delete duplicates (keeps one copy)\nDELETE FROM transactions \nWHERE id NOT IN (\n    SELECT MIN(id) \n    FROM transactions \n    GROUP BY date, description, amount\n);\n</code></pre>"},{"location":"troubleshooting/#2-prevent-future-duplicates","title":"2. Prevent Future Duplicates","text":"<p>Track uploaded files in <code>app.py</code>: <pre><code># Store file hash in database\nimport hashlib\n\ndef get_file_hash(file_path):\n    with open(file_path, 'rb') as f:\n        return hashlib.sha256(f.read()).hexdigest()\n\n# Check before processing\nfile_hash = get_file_hash(file_path)\n# ... check if hash exists in documents_metadata table\n</code></pre></p>"},{"location":"troubleshooting/#ui-issues","title":"UI Issues","text":""},{"location":"troubleshooting/#dashboard-not-loading","title":"\u274c Dashboard Not Loading","text":"<p>Symptoms: - Browser shows \"This site can't be reached\" - Page doesn't load</p> <p>Solutions:</p>"},{"location":"troubleshooting/#1-check-if-app-is-running","title":"1. Check if App is Running","text":"<pre><code># Look for this in terminal:\n\ud83c\udf10 Dashboard running at: http://127.0.0.1:8050\n</code></pre> <p>If not running: <pre><code>python -m finance_ai\n</code></pre></p>"},{"location":"troubleshooting/#2-try-different-url","title":"2. Try Different URL","text":"<pre><code># Try these:\nhttp://127.0.0.1:8050\nhttp://localhost:8050\nhttp://0.0.0.0:8050\n</code></pre>"},{"location":"troubleshooting/#3-check-firewall","title":"3. Check Firewall","text":"<p>macOS: <pre><code>System Preferences \u2192 Security &amp; Privacy \u2192 Firewall\n\u2192 Allow Python to accept incoming connections\n</code></pre></p> <p>Windows: <pre><code>Windows Defender Firewall \u2192 Allow an app\n\u2192 Add Python\n</code></pre></p>"},{"location":"troubleshooting/#upload-button-not-working","title":"\u274c Upload Button Not Working","text":"<p>Symptoms: - Click upload area, nothing happens - Drag &amp; drop doesn't work</p> <p>Solutions:</p>"},{"location":"troubleshooting/#1-check-browser-console","title":"1. Check Browser Console","text":"<p>Open developer tools: - Chrome/Edge: <code>F12</code> or <code>Cmd+Opt+I</code> (Mac) / <code>Ctrl+Shift+I</code> (Windows) - Look for JavaScript errors</p>"},{"location":"troubleshooting/#2-try-different-browser","title":"2. Try Different Browser","text":"<p>Test in: - Chrome - Firefox - Edge - Safari</p>"},{"location":"troubleshooting/#3-clear-browser-cache","title":"3. Clear Browser Cache","text":"<pre><code>Chrome: Cmd+Shift+Delete (Mac) / Ctrl+Shift+Delete (Windows)\nSelect \"Cached images and files\" \u2192 Clear\n</code></pre>"},{"location":"troubleshooting/#pdf-issues","title":"PDF Issues","text":""},{"location":"troubleshooting/#could-not-extract-text-from-pdf","title":"\u274c \"Could not extract text from PDF\"","text":"<p>Symptoms: - PDF upload succeeds but no transactions found - \"0 records processed\"</p> <p>Causes &amp; Solutions:</p>"},{"location":"troubleshooting/#1-scannedimage-pdf","title":"1. Scanned/Image PDF","text":"<p>Enable OCR:</p> macOSLinuxWindows <pre><code>brew install tesseract\n</code></pre> <pre><code>sudo apt-get install tesseract-ocr\n</code></pre> <p>Download from: https://github.com/UB-Mannheim/tesseract/wiki</p> <p>Then re-upload the PDF.</p>"},{"location":"troubleshooting/#2-password-protected-pdf","title":"2. Password-Protected PDF","text":"<p>Remove password first: <pre><code># Using qpdf (install: brew install qpdf)\nqpdf --password=PASSWORD --decrypt input.pdf output.pdf\n</code></pre></p>"},{"location":"troubleshooting/#3-corrupted-pdf","title":"3. Corrupted PDF","text":"<p>Try: - Re-download from bank - Open in PDF reader to verify - Convert to CSV instead</p>"},{"location":"troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"troubleshooting/#high-cpu-usage","title":"\u274c High CPU Usage","text":"<p>Symptoms: - Computer fans spinning loudly - System becomes slow - CPU usage at 100%</p> <p>Solutions:</p>"},{"location":"troubleshooting/#1-reduce-thread-count","title":"1. Reduce Thread Count","text":"<pre><code># In llm_handler.py\nn_threads=2  # Lower from 4 to 2\n</code></pre>"},{"location":"troubleshooting/#2-process-files-sequentially","title":"2. Process Files Sequentially","text":"<p>Don't upload many files at once: - Upload 1-2 files at a time - Wait for processing to complete</p>"},{"location":"troubleshooting/#3-close-background-apps","title":"3. Close Background Apps","text":"<p>Free up CPU by closing: - Web browsers - Other Python processes - Development tools</p>"},{"location":"troubleshooting/#high-memory-usage","title":"\u274c High Memory Usage","text":"<p>Symptoms: - System memory full - Computer becomes sluggish - Swap usage high</p> <p>Solutions:</p>"},{"location":"troubleshooting/#1-check-memory-usage","title":"1. Check Memory Usage","text":"macOSLinux <pre><code># Check memory\nvm_stat\n\n# Check process memory\nps aux | grep python\n</code></pre> <pre><code># Check memory\nfree -h\n\n# Check process memory\ntop -p $(pgrep -f \"python -m finance_ai\")\n</code></pre>"},{"location":"troubleshooting/#2-restart-app-periodically","title":"2. Restart App Periodically","text":"<pre><code># If processing many files\npkill -f \"python -m finance_ai\"\npython -m finance_ai\n</code></pre>"},{"location":"troubleshooting/#3-use-smaller-model","title":"3. Use Smaller Model","text":"<p>See Memory Error section above.</p>"},{"location":"troubleshooting/#getting-help","title":"Getting Help","text":"<p>If your issue isn't listed here:</p>"},{"location":"troubleshooting/#1-check-logs","title":"1. Check Logs","text":"<pre><code># Run with verbose output\npython -m finance_ai\n\n# Check for errors in terminal output\n</code></pre>"},{"location":"troubleshooting/#2-enable-debug-mode","title":"2. Enable Debug Mode","text":"<pre><code># In finance_ai/app.py\nif __name__ == '__main__':\n    app.run_server(debug=True)  # Enables detailed error messages\n</code></pre>"},{"location":"troubleshooting/#3-check-database","title":"3. Check Database","text":"<pre><code># Verify database integrity\nsqlite3 data/finance.db \"PRAGMA integrity_check;\"\n</code></pre>"},{"location":"troubleshooting/#4-test-installation","title":"4. Test Installation","text":"<pre><code>python scripts/test_installation.py\n</code></pre>"},{"location":"troubleshooting/#5-community-support","title":"5. Community Support","text":"<ul> <li>\ud83d\udcd6 Read the FAQ</li> <li>\ud83d\udc1b Open an issue on GitHub</li> <li>\ud83d\udcac Ask in discussions</li> </ul>"},{"location":"troubleshooting/#reset-recovery","title":"Reset &amp; Recovery","text":""},{"location":"troubleshooting/#clean-reset","title":"Clean Reset","text":"<p>\u26a0\ufe0f WARNING: This deletes all data!</p> <pre><code># Backup first\ncp data/finance.db data/finance_backup.db\n\n# Remove database\nrm data/finance.db\n\n# Remove temp files\nrm -rf data/temp/*\n\n# Restart app (will recreate database)\npython -m finance_ai\n</code></pre>"},{"location":"troubleshooting/#restore-from-backup","title":"Restore from Backup","text":"<pre><code># Copy backup\ncp data/finance_backup.db data/finance.db\n\n# Restart app\npython -m finance_ai\n</code></pre> <p>Prevention Tips</p> <ul> <li>Keep backups of your database</li> <li>Update dependencies regularly: <code>make export-reqs &amp;&amp; pip install --upgrade -r requirements.txt</code></li> <li>Monitor disk space and memory</li> <li>Test with small files first</li> </ul> <p>Still Stuck?</p> <p>If you can't solve your issue, please: 1. Check the FAQ 2. Search existing GitHub issues 3. Open a new issue with details (error messages, logs, steps to reproduce)</p>"},{"location":"user-guide/uploading/","title":"Uploading Files","text":"<p>Learn how to upload and process financial documents with Finance AI Dashboard.</p>"},{"location":"user-guide/uploading/#supported-file-formats","title":"Supported File Formats","text":"<p>Finance AI supports three main file types:</p> Format Extensions Use Case CSV <code>.csv</code> Bank exports, spreadsheets PDF <code>.pdf</code> Bank statements, invoices, receipts Text <code>.txt</code>, <code>.text</code> Manual entry, notes, pasted data <p>Universal Support</p> <p>The AI can understand almost any layout or format within these file types!</p>"},{"location":"user-guide/uploading/#upload-methods","title":"Upload Methods","text":""},{"location":"user-guide/uploading/#method-1-drag-drop","title":"Method 1: Drag &amp; Drop","text":"<pre><code>graph LR\n    A[Select File] --&gt; B[Drag to Upload Area]\n    B --&gt; C[Drop File]\n    C --&gt; D[Processing...]\n    D --&gt; E[\u2713 Success]\n\n    style E fill:#c8e6c9</code></pre> <ol> <li>Select your file in file explorer</li> <li>Drag it over the upload area (it will highlight)</li> <li>Drop to start processing</li> </ol>"},{"location":"user-guide/uploading/#method-2-click-to-browse","title":"Method 2: Click to Browse","text":"<ol> <li>Click anywhere in the Upload Area</li> <li>File picker opens</li> <li>Select your file</li> <li>Processing starts automatically</li> </ol>"},{"location":"user-guide/uploading/#method-3-multiple-files","title":"Method 3: Multiple Files","text":"<p>Upload multiple files at once:</p> <ol> <li>Select multiple files (Ctrl+Click or Cmd+Click)</li> <li>Drag &amp; drop or use file picker</li> <li>Files process sequentially</li> </ol> <pre><code>Processing: chase_jan.csv... \u2713 42 records\nProcessing: amex_jan.pdf... \u2713 38 records\nProcessing: receipts.txt... \u2713 12 records\n\nTotal: 92 records processed \ud83e\udd16\n</code></pre>"},{"location":"user-guide/uploading/#csv-files","title":"CSV Files","text":""},{"location":"user-guide/uploading/#format-requirements","title":"Format Requirements","text":"<p>CSV files should have financial data in columns. The AI understands various formats:</p> <p>Standard Format: <pre><code>Date,Description,Amount\n2025-01-15,Whole Foods Market,-45.67\n2025-01-16,Coffee Shop,-5.25\n2025-01-20,Salary,3500.00\n</code></pre></p> <p>Bank Format: <pre><code>Transaction Date,Posted Date,Merchant Name,Amount,Category\n01/15/2025,01/16/2025,WHOLEFDS #123,-45.67,Groceries\n</code></pre></p> <p>Custom Format: <pre><code>When,What,How Much\nJan 15,Whole Foods,$45.67\nJan 16,Starbucks,$5.25\n</code></pre></p> <p>Flexible Columns</p> <p>The AI doesn't require specific column names - it understands the meaning of the data!</p>"},{"location":"user-guide/uploading/#common-csv-sources","title":"Common CSV Sources","text":""},{"location":"user-guide/uploading/#chase-bank","title":"Chase Bank","text":"<p>Export from Chase.com:</p> <ol> <li>Log in to Chase Online Banking</li> <li>Navigate to Statements &amp; Documents</li> <li>Select \"Download transactions\"</li> <li>Choose \"CSV\" format</li> <li>Upload to Finance AI</li> </ol> <p>Expected columns: <pre><code>Details,Posting Date,Description,Amount,Type,Balance\n</code></pre></p>"},{"location":"user-guide/uploading/#bank-of-america","title":"Bank of America","text":"<p>Export from BankofAmerica.com:</p> <ol> <li>Log in to Online Banking</li> <li>Click \"Download transactions\"</li> <li>Select CSV/Excel format</li> <li>Upload to Finance AI</li> </ol> <p>Expected columns: <pre><code>Date,Description,Amount,Running Bal.\n</code></pre></p>"},{"location":"user-guide/uploading/#american-express","title":"American Express","text":"<p>Export from Amex.com:</p> <ol> <li>Go to Statements &amp; Activity</li> <li>Click \"Download\"</li> <li>Select CSV format</li> <li>Upload to Finance AI</li> </ol> <p>Expected columns: <pre><code>Date,Description,Amount\n</code></pre></p>"},{"location":"user-guide/uploading/#handling-encoding-issues","title":"Handling Encoding Issues","text":"<p>If you see garbled text (like <code>\u00c3\u00a9</code> instead of <code>\u00e9</code>):</p> <p>Option 1: Re-save with UTF-8</p> <ol> <li>Open CSV in Excel/Numbers</li> <li>File \u2192 Save As</li> <li>Set encoding to \"UTF-8\"</li> <li>Upload new file</li> </ol> <p>Option 2: Use Google Sheets</p> <ol> <li>Upload CSV to Google Sheets</li> <li>File \u2192 Download \u2192 CSV</li> <li>Google Sheets auto-converts to UTF-8</li> </ol>"},{"location":"user-guide/uploading/#pdf-files","title":"PDF Files","text":""},{"location":"user-guide/uploading/#what-works","title":"What Works","text":"<p>Finance AI can extract transactions from:</p> <ul> <li>\u2705 Bank statements</li> <li>\u2705 Credit card statements</li> <li>\u2705 Invoices</li> <li>\u2705 Receipts</li> <li>\u2705 Financial reports</li> <li>\u2705 Even scanned/image PDFs (with OCR)</li> </ul>"},{"location":"user-guide/uploading/#pdf-processing-flow","title":"PDF Processing Flow","text":"<pre><code>graph TD\n    A[Upload PDF] --&gt; B{Text-based?}\n    B --&gt;|Yes| C[Extract Text]\n    B --&gt;|No| D[OCR Scan]\n    C --&gt; E[AI Analysis]\n    D --&gt; E\n    E --&gt; F[Extract Transactions]\n    F --&gt; G[Store in Database]\n\n    style C fill:#e8f5e9\n    style D fill:#fff9c4</code></pre>"},{"location":"user-guide/uploading/#example-bank-statement","title":"Example: Bank Statement","text":"<p>Typical Statement:</p> <pre><code>CHASE BANK\nAccount: ****1234\nStatement Period: 01/01/2025 - 01/31/2025\n\nTRANSACTIONS:\nDate       Description              Amount\n01/15      WHOLE FOODS MARKET       $45.67\n01/16      STARBUCKS #12345          $5.25\n01/20      SHELL GAS STATION        $52.00\n01/22      AMAZON.COM               $28.99\n01/25      PAYROLL DEPOSIT        $3,500.00\n\nSUMMARY:\nBeginning Balance: $2,000.00\nTotal Credits: $3,500.00\nTotal Debits: -$131.91\nEnding Balance: $5,368.09\n</code></pre> <p>The AI extracts: - 5 transactions - Proper categorization - Date normalization - Amount parsing (handles $ and commas)</p>"},{"location":"user-guide/uploading/#scanned-pdfs-ocr","title":"Scanned PDFs &amp; OCR","text":"<p>If your PDF is a scanned image, Finance AI can still read it!</p> <p>Requirements:</p> <ol> <li>Install Tesseract OCR (optional but recommended)</li> </ol> macOSLinuxWindows <pre><code>brew install tesseract\n</code></pre> <pre><code>sudo apt-get install tesseract-ocr\n</code></pre> <p>Download from: https://github.com/UB-Mannheim/tesseract/wiki</p> <ol> <li>Upload the scanned PDF</li> <li>OCR runs automatically if text extraction fails</li> </ol> <p>OCR Accuracy</p> <p>OCR works best with: - High-resolution scans (300+ DPI) - Clear, readable text - Proper orientation (not rotated)</p>"},{"location":"user-guide/uploading/#pdf-best-practices","title":"PDF Best Practices","text":"<p>\u2705 Do: - Use original PDFs (not re-scanned) - Keep file size reasonable (&lt;50MB) - Ensure text is selectable (if possible)</p> <p>\u274c Don't: - Upload password-protected PDFs - Use extremely low-quality scans - Rotate documents before uploading (AI can handle rotation)</p>"},{"location":"user-guide/uploading/#text-files","title":"Text Files","text":""},{"location":"user-guide/uploading/#plain-text-input","title":"Plain Text Input","text":"<p>Simply paste or type financial data:</p> <pre><code>Spent $45.67 at Whole Foods on January 15th\nCoffee was $5.25 at Starbucks yesterday  \nGot gas for $52.00 last week\nSalary deposited: $3,500\n</code></pre> <p>The AI will: 1. Parse dates (relative like \"yesterday\" or absolute) 2. Extract amounts (handles $ and various formats) 3. Identify merchants 4. Guess categories</p>"},{"location":"user-guide/uploading/#structured-text","title":"Structured Text","text":"<p>You can also use basic structure:</p> <pre><code>Transactions for January 2025:\n\nJan 15 - Whole Foods - $45.67 (groceries)\nJan 16 - Starbucks - $5.25 (coffee)\nJan 20 - Shell - $52.00 (gas)\nJan 22 - Amazon - $28.99 (shopping)\nJan 25 - Salary - $3,500.00 (income)\n</code></pre>"},{"location":"user-guide/uploading/#mixed-format","title":"Mixed Format","text":"<p>Even mixed notes work:</p> <pre><code>Grocery shopping on 1/15: Whole Foods $45.67\nMorning coffee @ Starbucks = $5.25 (1/16)\nFilled up tank - $52 - January 20th\nAmazon purchase: $28.99\nPaycheck received 01/25/2025 - $3500\n</code></pre> <p>The AI understands it all! \ud83e\udde0</p>"},{"location":"user-guide/uploading/#processing-status","title":"Processing Status","text":""},{"location":"user-guide/uploading/#success-messages","title":"Success Messages","text":"<pre><code>\u2713 chase_statement.pdf: 42 records processed \ud83e\udd16\n\u2713 amex_jan.csv: 38 records processed \ud83e\udd16\n\u2713 receipts.txt: 12 records processed \ud83e\udd16\n</code></pre>"},{"location":"user-guide/uploading/#what-happens-during-processing","title":"What Happens During Processing","text":"<pre><code>sequenceDiagram\n    participant U as You\n    participant D as Dashboard\n    participant A1 as Agent 1\n    participant A2 as Agent 2\n    participant A3 as Agent 3\n    participant DB as Database\n\n    U-&gt;&gt;D: Upload file\n    D-&gt;&gt;A1: Extract\n    Note over A1: Read &amp; analyze&lt;br/&gt;(1-2 sec)\n    A1-&gt;&gt;A2: Organize\n    Note over A2: Structure data&lt;br/&gt;(1-2 sec)\n    A2-&gt;&gt;A3: Store\n    Note over A3: Write to DB&lt;br/&gt;(&lt;1 sec)\n    A3-&gt;&gt;DB: Insert\n    DB-&gt;&gt;D: Success\n    D-&gt;&gt;U: \u2713 Records processed \ud83e\udd16</code></pre> <p>Timing: - First upload: 7-15 seconds (loading AI model) - Subsequent uploads: 2-5 seconds</p>"},{"location":"user-guide/uploading/#error-messages","title":"Error Messages","text":""},{"location":"user-guide/uploading/#file-format-not-supported","title":"\u274c \"File format not supported\"","text":"<p>Cause: File is not CSV, PDF, or TXT</p> <p>Solution: Convert to supported format or save as CSV</p>"},{"location":"user-guide/uploading/#could-not-extract-transactions","title":"\u274c \"Could not extract transactions\"","text":"<p>Causes: - File is empty - No financial data found - PDF is corrupted</p> <p>Solutions: 1. Check file content 2. Try re-downloading from bank 3. Convert to CSV</p>"},{"location":"user-guide/uploading/#llm-not-available","title":"\u274c \"LLM not available\"","text":"<p>Cause: AI model not loaded</p> <p>Solution: See Installation Guide</p>"},{"location":"user-guide/uploading/#upload-limits","title":"Upload Limits","text":"Limit Value Max file size 100 MB Max files at once 10 files Concurrent uploads 1 at a time <p>Large Files</p> <p>For files &gt;100MB, consider splitting into smaller chunks or exporting by month.</p>"},{"location":"user-guide/uploading/#data-privacy","title":"Data Privacy","text":"<pre><code>graph LR\n    A[Your File] --&gt; B[Your Computer]\n    B --&gt; C[Local AI]\n    C --&gt; D[Local Database]\n\n    B -.-&gt;|Never| E[\u274c Internet]\n    B -.-&gt;|Never| F[\u274c Cloud]\n    B -.-&gt;|Never| G[\u274c External APIs]\n\n    style E fill:#ffcdd2\n    style F fill:#ffcdd2\n    style G fill:#ffcdd2</code></pre> <p>Your data never leaves your machine: - \u2705 Files stay on your computer - \u2705 AI runs locally - \u2705 Database is local SQLite - \u2705 No internet required - \u2705 100% private</p>"},{"location":"user-guide/uploading/#tips-for-best-results","title":"Tips for Best Results","text":""},{"location":"user-guide/uploading/#1-consistent-date-formats","title":"1. Consistent Date Formats","text":"<p>While the AI handles various formats, consistency helps:</p> <p>Good: <pre><code>Date,Description,Amount\n2025-01-15,Whole Foods,-45.67\n2025-01-16,Starbucks,-5.25\n</code></pre></p> <p>Also Fine: <pre><code>Date,Description,Amount\n01/15/2025,Whole Foods,-45.67\n01/16/2025,Starbucks,-5.25\n</code></pre></p>"},{"location":"user-guide/uploading/#2-include-currency","title":"2. Include Currency","text":"<p>If using multiple currencies, include symbols:</p> <pre><code>Date,Description,Amount\n2025-01-15,Whole Foods,-\u20ac45.67\n2025-01-16,Starbucks,-\u00a35.25\n</code></pre>"},{"location":"user-guide/uploading/#3-descriptive-merchants","title":"3. Descriptive Merchants","text":"<p>More context = better categorization:</p> <p>Better: <pre><code>Whole Foods Market #123, Seattle WA\n</code></pre></p> <p>vs: <pre><code>Purchase\n</code></pre></p>"},{"location":"user-guide/uploading/#4-negative-for-expenses","title":"4. Negative for Expenses","text":"<p>Use negative amounts for spending:</p> <pre><code>Amount\n-45.67  # Expense\n3500.00 # Income\n</code></pre>"},{"location":"user-guide/uploading/#next-steps","title":"Next Steps","text":"<ul> <li>View Dashboard - Explore your data</li> <li>Manage Categories - Customize categories</li> <li>Database Schema - Where data is stored</li> </ul> <p>Upload Complete</p> <p>Your transactions are now in the database and ready to analyze!</p>"}]}